{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86aafaef",
   "metadata": {
    "id": "86aafaef"
   },
   "source": [
    "## Harnessing NLP for Historical Text Analysis: A Case Study on the Indus Valley Civilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9f581",
   "metadata": {
    "id": "cee9f581"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49ed3bd-c12e-40af-9c2a-d7a522a48b47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c49ed3bd-c12e-40af-9c2a-d7a522a48b47",
    "outputId": "d9826eec-6c98-4d2f-c1b7-8df8a23a383e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "## Pre-loading the model before data source to optimize memory\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L-12-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c972c76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c972c76",
    "outputId": "abd74596-319c-48af-fe43-d1bd64eee53e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/4psym4l52gzbg9swfsnj2vzm0000gn/T/ipykernel_77655/544004033.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sahilkhanna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sahilkhanna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sahilkhanna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/12.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/12.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/12.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/12.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/12.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/12.8 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m10.3/12.8 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (70.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "import urllib\n",
    "import pysrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain, combinations\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import faiss\n",
    "import time\n",
    "import emoji\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "import textacy\n",
    "import textacy.preprocessing as tprep\n",
    "import subprocess\n",
    "print(subprocess.getoutput(\"python -m spacy download en_core_web_sm\"))\n",
    "import contractions\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "from gensim.models import LdaModel, Word2Vec\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "mystopwords = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models #don't skip this\n",
    "\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "LANGUAGE = \"english\"\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.types import DataPoint\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import eli5\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4343616",
   "metadata": {
    "id": "d4343616"
   },
   "source": [
    "## Loading Text Source\n",
    "\n",
    "* This text source is a wikipedia page about the Indus Valley Civilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974831fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "974831fa",
    "outputId": "b472a96d-a6c7-4965-e1d9-b984e04b4f57"
   },
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Indus_Valley_Civilisation\"\n",
    "html = urllib.request.urlopen(url)\n",
    "\n",
    "# clean out the html get only the text\n",
    "soupified = BeautifulSoup(html, \"html.parser\")\n",
    "data_all = soupified.get_text().strip()\n",
    "data = data_all[3946:78891]\n",
    "#data = data_all[0:78834]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f031fc62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "f031fc62",
    "outputId": "c6ac0f56-ff57-4370-bf37-e495c2e1143c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation[1] (IVC), also k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2][a] Together with ancient Egypt and Mesopot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3][b] The civilisation flourished both in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2][4]\\nThe term Harappan is sometimes applied...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5][c] The discovery of Harappa and soon after...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The Indus Valley Civilisation[1] (IVC), also k...\n",
       "1  [2][a] Together with ancient Egypt and Mesopot...\n",
       "2  [3][b] The civilisation flourished both in the...\n",
       "3  [2][4]\\nThe term Harappan is sometimes applied...\n",
       "4  [5][c] The discovery of Harappa and soon after..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.DataFrame(\n",
    "    nltk.sent_tokenize(data),\n",
    "    columns = [\"text\"]\n",
    ")\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16e2b3",
   "metadata": {
    "id": "1f16e2b3"
   },
   "source": [
    "### Calculate the Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0124a73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0124a73",
    "outputId": "95522f70-1af4-4e9b-ba2f-c4c00a7ea78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 14236\n"
     ]
    }
   ],
   "source": [
    "# show how many tokens the text source has?\n",
    "print(\"Number of tokens:\", len(nltk.word_tokenize(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6ec65",
   "metadata": {
    "id": "03b6ec65"
   },
   "source": [
    "### Summary of the Text Source\n",
    "\n",
    "**&nbsp;1. Introduction of the text source.**\n",
    "\n",
    "The **Wikipedia article** on the `Indus Valley Civilization (IVC)` serves as the primary source for this project. This publicly accessible and comprehensive page offers a detailed overview of one of the earliest urban cultures in the world, a civilization that thrived in the basins of the Indus River. The article is a treasure trove of information, with sections dedicated to the civilization's discovery, geographical reach, major sites, culture, economy, technology, writing system, and its eventual decline. The IVC, with its advanced urban planning and unique cultural aspects, holds a significant place in the narrative of ancient urban development.<br>\n",
    "The text source contains **14236 tokens.**\n",
    "\n",
    "**&nbsp;2. Brief description of the summary of the text. My interest in analyzing this data. What questions will I answer given from this dataset?**\n",
    "\n",
    "**Brief Description of the Text**<br>\n",
    "The Wikipedia article on the IVC presents a detailed account of this ancient civilization, recognized for its advanced urban planning, architecture, and social organization. It describes the layout of major cities like Harappa and Mohenjo-Daro, noting features such as the world's first known urban sanitation systems. The article also explores the economic practices, trade routes, cultural aspects, and mysterious script of the IVC, which remains undeciphered. It discusses various theories about the decline of civilization, including climate change and invasion theories.\n",
    "\n",
    "**Interest in Analyzing This Text**<br>\n",
    "The Indus Valley Civilization was an ancient society that significantly contributed to history. I have always been fascinated by its history, art, and innovations. To truly understand its complexities and achievements, I must delve deeper into its urban planning techniques, architecture, artistic expressions, technological advancements, culture and societal structure, and reasons for decline. Fortunately, the Wikipedia page on this civilization provides me with a dataset that can help me answer these questions. By exploring this dataset, I can gain valuable insights into this remarkable society.\n",
    "\n",
    "Furthermore, using NLP to analyze a detailed and comprehensive text like a Wikipedia article demonstrates how modern AI tools can aid in historical research, making it more accessible and informative through technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134d492-61d7-41ba-8f2d-acdf94ee1614",
   "metadata": {
    "id": "3134d492-61d7-41ba-8f2d-acdf94ee1614"
   },
   "source": [
    "## Processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab9ff7a-f7d8-44fd-8458-340e905ad13b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ab9ff7a-f7d8-44fd-8458-340e905ad13b",
    "outputId": "43d480da-d5c0-4696-9fc0-99c2e4ee8fcd"
   },
   "outputs": [],
   "source": [
    "# Functions to clean and normalize the text\n",
    "def normalize(text):\n",
    "    text = tprep.normalize.hyphenated_words(text)\n",
    "    text = tprep.normalize.quotation_marks(text)\n",
    "    text = tprep.normalize.unicode(text)\n",
    "    text = tprep.remove.accents(text)\n",
    "    text = tprep.replace.phone_numbers(text)\n",
    "    text = tprep.replace.urls(text)\n",
    "    text = tprep.replace.emails(text)\n",
    "    text = tprep.replace.user_handles(text)\n",
    "    text = tprep.replace.emojis(text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Function to clean text\n",
    "def clean_up(text):\n",
    "    text = re.sub('</?[a-z]>', ' ', text)\n",
    "    text = re.sub('♪', ' ', text)\n",
    "    text = re.sub(r'\\[\\w+\\]', '', text)\n",
    "    text = re.sub(\"\\\\n\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# Tokenize, remove stopwords, and lemmatize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to process text\n",
    "def process_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    words = [word for word in words if word.isalnum()]  # Remove punctuation\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatize\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c208b8-96b7-4ec0-a050-ab88e9733452",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "85c208b8-96b7-4ec0-a050-ab88e9733452",
    "outputId": "d4b8aeeb-6139-4f0d-d0a1-9069387d6956"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation[1] (IVC), also k...</td>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>The Indus Valley Civilisation IVC also known I...</td>\n",
       "      <td>the indus valley civilisation ivc also known i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2][a] Together with ancient Egypt and Mesopot...</td>\n",
       "      <td>Together with ancient Egypt and Mesopotamia, ...</td>\n",
       "      <td>Together ancient Egypt Mesopotamia one three e...</td>\n",
       "      <td>together ancient egypt mesopotamia one three e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3][b] The civilisation flourished both in the...</td>\n",
       "      <td>The civilisation flourished both in the alluv...</td>\n",
       "      <td>The civilisation flourished alluvial plain Ind...</td>\n",
       "      <td>the civilisation flourished alluvial plain ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2][4]\\nThe term Harappan is sometimes applied...</td>\n",
       "      <td>The term Harappan is sometimes applied to the...</td>\n",
       "      <td>The term Harappan sometimes applied Indus civi...</td>\n",
       "      <td>the term harappan sometimes applied indus civi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5][c] The discovery of Harappa and soon after...</td>\n",
       "      <td>The discovery of Harappa and soon afterwards ...</td>\n",
       "      <td>The discovery Harappa soon afterwards culminat...</td>\n",
       "      <td>the discovery harappa soon afterwards culminat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Indus Valley Civilisation[1] (IVC), also k...   \n",
       "1  [2][a] Together with ancient Egypt and Mesopot...   \n",
       "2  [3][b] The civilisation flourished both in the...   \n",
       "3  [2][4]\\nThe term Harappan is sometimes applied...   \n",
       "4  [5][c] The discovery of Harappa and soon after...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1   Together with ancient Egypt and Mesopotamia, ...   \n",
       "2   The civilisation flourished both in the alluv...   \n",
       "3   The term Harappan is sometimes applied to the...   \n",
       "4   The discovery of Harappa and soon afterwards ...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  The Indus Valley Civilisation IVC also known I...   \n",
       "1  Together ancient Egypt Mesopotamia one three e...   \n",
       "2  The civilisation flourished alluvial plain Ind...   \n",
       "3  The term Harappan sometimes applied Indus civi...   \n",
       "4  The discovery Harappa soon afterwards culminat...   \n",
       "\n",
       "                                          normalized  \n",
       "0  the indus valley civilisation ivc also known i...  \n",
       "1  together ancient egypt mesopotamia one three e...  \n",
       "2  the civilisation flourished alluvial plain ind...  \n",
       "3  the term harappan sometimes applied indus civi...  \n",
       "4  the discovery harappa soon afterwards culminat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning\n",
    "DF_new = DF.copy()\n",
    "DF[\"clean\"] = DF[\"text\"].apply(clean_up)\n",
    "DF[\"processed\"] = DF[\"clean\"].apply(process_text)\n",
    "\n",
    "# Normalize the rest of the text by using textacy.\n",
    "#DF[\"normalized\"] = DF[\"clean\"].apply(normalize)\n",
    "DF[\"normalized\"] = DF[\"processed\"].apply(normalize)\n",
    "#DF[\"normalize\"] = DF[\"processed\"].apply(normalize)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37602c9e-18fe-490e-a103-b2488d7b04e0",
   "metadata": {
    "id": "37602c9e-18fe-490e-a103-b2488d7b04e0",
    "outputId": "97b9b825-19cd-4a21-bc57-c20a9a68e547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesopotamia\n",
      "None\n",
      "None\n",
      "----\n",
      "\n",
      "asia\n",
      "aria\n",
      "{'aria', 'psia'}\n",
      "----\n",
      "\n",
      "civilisation\n",
      "civilization\n",
      "{'civilization'}\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine spelling errors in at least one row of the dataset.\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(nltk.word_tokenize(DF[\"normalized\"].iloc[1])) # or DF['normalize'][0]\n",
    "\n",
    "for word in misspelled:\n",
    "    # what is the word\n",
    "    print(word)\n",
    "\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))\n",
    "\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a069d84-0bd5-4738-8719-fe18815d4f66",
   "metadata": {
    "id": "4a069d84-0bd5-4738-8719-fe18815d4f66"
   },
   "source": [
    "### Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835436ef-bd64-4c51-a6f2-7de662552793",
   "metadata": {
    "id": "835436ef-bd64-4c51-a6f2-7de662552793",
    "outputId": "e3644433-ce64-440e-fe05-d82b0fc0c4d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>specific_pos</th>\n",
       "      <th>universal_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indus</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valley</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>civilisation</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ivc</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>indus</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>towards</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>himalayan</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>foothill</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>basin</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             token specific_pos universal_pos\n",
       "0              the           DT           DET\n",
       "1            indus           NN          NOUN\n",
       "2           valley           NN          NOUN\n",
       "3     civilisation           NN          NOUN\n",
       "4              ivc          NNP         PROPN\n",
       "...            ...          ...           ...\n",
       "6745         indus           NN          NOUN\n",
       "6746       towards           IN           ADP\n",
       "6747     himalayan           JJ           ADJ\n",
       "6748      foothill           NN          NOUN\n",
       "6749         basin           NN          NOUN\n",
       "\n",
       "[6750 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part of speech tagging\n",
    "#whole_text = \" \".join(DF[\"clean\"].to_list())\n",
    "whole_text = \" \".join(DF[\"normalized\"].to_list())\n",
    "\n",
    "spacy_pos_tagged = [(str(word), word.tag_, word.pos_) for word in nlp(whole_text)]\n",
    "DF_tags = pd.DataFrame(spacy_pos_tagged, columns = [\"token\", \"specific_pos\", \"universal_pos\"])\n",
    "DF_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967d96a9-078d-41ef-a6d5-a63d2a81be20",
   "metadata": {
    "id": "967d96a9-078d-41ef-a6d5-a63d2a81be20",
    "outputId": "b796d06b-5d14-4eb9-f618-65c0395f18f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universal_pos\n",
       "NOUN     2545\n",
       "PROPN    1448\n",
       "VERB      977\n",
       "ADJ       915\n",
       "ADV       296\n",
       "NUM       230\n",
       "ADP       117\n",
       "DET       111\n",
       "PRON       36\n",
       "SCONJ      34\n",
       "AUX        28\n",
       "X           5\n",
       "CCONJ       5\n",
       "PART        1\n",
       "INTJ        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_tags.query(\"universal_pos != 'PUNCT'\", inplace=True)\n",
    "DF_tags[\"universal_pos\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca16265-c6c7-4a1f-92ee-86072069ab51",
   "metadata": {
    "id": "cca16265-c6c7-4a1f-92ee-86072069ab51",
    "outputId": "ad7cdfb4-8ac7-4bba-bf78-eb84f42ebc7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>universal_pos</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>total_tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mehrgarh</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bce</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harappan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>culture</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archaeologist</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artifact</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "universal_pos  ADJ  ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  \\\n",
       "token                                                                        \n",
       "mehrgarh         2    0    0    0      0    0     0     8    0     0     0   \n",
       "bce              0    0    0    3      0    0     0     3    0     0     0   \n",
       "indus            0    0    0    0      0    0     0   108    0     0     0   \n",
       "site             0    0    0    0      0    0     0    66    0     0     0   \n",
       "harappan         0    0    0    0      0    0     0    60    0     0     0   \n",
       "seal             0    0    0    0      0    0     0    46    0     0     0   \n",
       "culture          0    0    0    0      0    0     0    37    0     0     0   \n",
       "language         0    0    0    0      0    0     0    14    0     0     0   \n",
       "archaeologist    0    0    0    0      0    0     0     6    0     0     0   \n",
       "artifact         1    0    0    0      0    0     0     5    0     0     0   \n",
       "\n",
       "universal_pos  PROPN  SCONJ  VERB  X  total_tags  \n",
       "token                                             \n",
       "mehrgarh          11      0     5  0           4  \n",
       "bce                2      0    39  0           4  \n",
       "indus             23      0     3  0           3  \n",
       "site               3      0     1  0           3  \n",
       "harappan          31      0     2  0           3  \n",
       "seal               1      0     1  0           3  \n",
       "culture           17      0     2  0           3  \n",
       "language           1      0     1  0           3  \n",
       "archaeologist      3      0     1  0           3  \n",
       "artifact           1      0     0  0           3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_cross_tabs = pd.crosstab(DF_tags[\"token\"], DF_tags[\"universal_pos\"])\n",
    "DF_cross_tabs[\"total_tags\"] = DF_cross_tabs.astype(bool).sum(axis=1)\n",
    "\n",
    "#DF_cross_tabs.sort_values([\"total_tags\", \"NOUN\", \"PROPN\"], ascending=False).head(10)\n",
    "#DF_cross_tabs.query(\"SPACE== 0 & SYM== 0 & X== 0\").sort_values([\"total_tags\", \"NOUN\",\"PROPN\"], ascending=False).head(10)\n",
    "DF_cross_tabs.query(\"X== 0\").sort_values([\"total_tags\", \"NOUN\",\"PROPN\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8641f26-d7bb-44cb-b702-5487bab1ea57",
   "metadata": {
    "id": "f8641f26-d7bb-44cb-b702-5487bab1ea57"
   },
   "source": [
    "### Processing Text Summary\n",
    "\n",
    "**&nbsp;1. Summarizing the results from the raw text and part of the speech analysis section.**\n",
    "\n",
    "The raw text analysis and the part of speech (POS) tagging provided significant insights into the structure and content of the Indus Valley Civilization Wikipedia article.<br>\n",
    "The raw text processing involved cleaning operations such as removing special characters and HTML tags, standardizing text formatting, and eliminating citations and extraneous metadata. Methods like `regular expressions`, `nltk`, and the `textacy` library were used to identify the errors and strip unnecessary elements like _misplaced punctuation, stopwords, and citation notes(e.g., [1], [2])_. This was crucial for ensuring that the subsequent NLP tasks operated on clean data, yielding more accurate and meaningful results. Additionally, normalization techniques are used to standardize text, such as converting it to _lowercase and removing accents_, which helps reduce the data's complexity and variability. These steps are crucial as they directly impact the quality and reliability of downstream NLP tasks. The focus on removing impurities like suspicious characters was particularly important as they could lead to misinterpretations of the dataset's content. The NLP model can perform more effectively and provide more accurate insights by ensuring the data is clean and uniform.\n",
    "\n",
    "**Part-of-Speech Tagging analysis**\n",
    "\n",
    "POS tagging allowed for a detailed breakdown of the grammatical components within the text, identifying nouns, verbs, adjectives, etc., which helped in understanding the focus and narrative style of the article. Most notably, the prominence of nouns related to geographical locations, cultural terms, and historical periods highlighted the descriptive and factual nature of the text. Below is the summary from the POS analysis:\n",
    "\n",
    "1. The most common part of speech in the analyzed text are `NOUN`, with `2545` occurrences.\n",
    "2. There are words in the text that serve as multiple parts of speech. For example, the word `mehrgarh` appears as an adjective, verb, noun, and proper noun. Other words with multiple tags include `indus`, `harappan`, `culture`,  and `language`. This shows the flexibility of language usage in context, highlighting how the same word can serve different functions depending on its use in sentences.\n",
    "3. After examining the most common nouns and verbs, the proper nouns are predominant. This likely points to a text rich in specific references, which could indicate historical or descriptive content. Verbs, while less frequent, could give clues about the predominant activities or processes described, further aiding in understanding the text's focus or narrative style.\n",
    "\n",
    "However, the process was challenging. Handling the diversity of data formats within the article, such as lists, tables, and different section headings, was initially challenging as these elements required different cleaning strategies to ensure uniform text input for analysis. Implementing a more robust text preprocessing pipeline that automatically detects and appropriately handles various data formats could enhance efficiency and accuracy. Regarding normalization, techniques like lemmatization proved essential in reducing words to their base or dictionary form, which helps consolidate the variations of a word to a single entry, thus simplifying the analysis. It was surprising to observe the high frequency of certain cultural and geographical terms, which initially seemed less central to the narrative but highlighted underlying thematic emphases, such as trade routes and architectural features. This revelation underscores the importance of comprehensive preprocessing and detailed POS tagging in revealing subtle but significant aspects of text content in historical articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd499c-719b-4441-9694-17c46b640705",
   "metadata": {
    "id": "eebd499c-719b-4441-9694-17c46b640705"
   },
   "source": [
    "## Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d371351c-4148-4248-936d-130c396b9a2c",
   "metadata": {
    "id": "d371351c-4148-4248-936d-130c396b9a2c"
   },
   "source": [
    "### KPE\n",
    "\n",
    "* Use textacy to find the key phrases in the text.<br>\n",
    "* Using textacy utilities, combine like key phrases.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4214ff-864c-42b0-bc79-0dd2c3a18d56",
   "metadata": {
    "id": "6a4214ff-864c-42b0-bc79-0dd2c3a18d56",
    "outputId": "f5f5be9f-254d-4e1e-9ca8-b576e615058f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mature Harappan Mature Harappan Period',\n",
       " 'Early Harappan Early Harappan Period',\n",
       " 'Indus River Valley site',\n",
       " 'Indus Valley Civilisation(3300–1300 BC',\n",
       " 'large Late Harappan site']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KPE\n",
    "#whole_text = \" \".join(DF[\"normalized\"].to_list())\n",
    "whole_text = \" \".join(DF[\"clean\"].to_list())\n",
    "# build an english language for textacy pipe\n",
    "en = textacy.load_spacy_lang(\"en_core_web_sm\", disable=(\"parser\"))\n",
    "\n",
    "# build a processor for textacy using spacy and process text\n",
    "doc = textacy.make_spacy_doc(whole_text, lang = en)\n",
    "\n",
    "# text rank algorithm\n",
    "[kps for kps, weights in textacy.extract.keyterms.textrank(doc, normalize = \"lemma\",  topn = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25137977-8bf4-44c3-b309-fd6bdc4ab30b",
   "metadata": {
    "id": "25137977-8bf4-44c3-b309-fd6bdc4ab30b",
    "outputId": "50f7c409-78f7-4cf8-b82a-ba26218056e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Mature Harappan Mature Harappan Period'}, {'Indus Valley Civilisation(3300–1300 BC'}, {'Early Harappan Early Harappan Period'}, {'Mature Harappan culture(2600–1900 BC'}, {'Early Harappan culture(3300–2600 BC'}, {'large Late Harappan site'}, {'Indus River Valley site'}, {'early Harappan culture'}, {'Mature Harappan site'}, {'Indus Valley site'}]\n"
     ]
    }
   ],
   "source": [
    "terms = set([term for term, weight in textacy.extract.keyterms.textrank(doc)])\n",
    "print(textacy.extract.utils.aggregate_term_variants(terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af4e8c-e8b5-442e-8f0c-ba923eff4497",
   "metadata": {
    "id": "c3af4e8c-e8b5-442e-8f0c-ba923eff4497"
   },
   "source": [
    "#### KPE Summary\n",
    "\n",
    "**&nbsp;1. What did I learn about the text by using keyphrase analysis?**\n",
    "\n",
    "The key phrase analysis reveals the following keyphrases:\n",
    "\n",
    "1. Mature Harappan Period\n",
    "2. Early Harappan Period\n",
    "3. Indus River Valley site\n",
    "4. Indus Valley Civilisation\n",
    "5. large Late Harappan site\n",
    "\n",
    "Additionally, the `aggregate_term_variants` function from `textacy` was used, which combines similar or related terms. The results include aggregated keyphrases like:\n",
    "\n",
    "- Indus Valley Civilisation(3300–1300 BC)\n",
    "- Mature Harappan culture(2600–1900 BC)\n",
    "- Early Harappan culture(3300–2600 BC)\n",
    "- large Late Harappan site\n",
    "- Indus River Valley site\n",
    "- Mature Harappan site\n",
    "\n",
    "This analysis shows that the text contains the following:\n",
    "- Discussions related to the Indus Valley Civilization.\n",
    "- Focusing on different cultural phases (early, late, and mature).\n",
    "- The geographical aspect (river valley sites).\n",
    "- Specific time frames (3300–1300 BC, 3300–2600 BC, 2600–1900 BC) indicate a historical and archaeological context in the text.\n",
    "\n",
    "The key phrase analysis helped to condense the text into core themes, making it apparent that the central subject is the historical and cultural study of the Indus Valley Civilization. It underscores the relevance of specific archeological sites and cultural periods, which could be pivotal for further studies or focused readings. This kind of analysis is useful for quickly understanding the main topics in large volumes of text or preparing for more in-depth research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ec513-4480-4ed1-b7b9-c496a0181088",
   "metadata": {
    "id": "149ec513-4480-4ed1-b7b9-c496a0181088"
   },
   "source": [
    "### NER\n",
    "\n",
    "* Use spaCy to extract named entities.<br>\n",
    "* Create a summary of the named entities.<br>\n",
    "* Apply Snorkel to the data to show any relationship between names.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea9256d-4379-4b3d-b595-1af7edf984bd",
   "metadata": {
    "id": "0ea9256d-4379-4b3d-b595-1af7edf984bd",
    "outputId": "337fa799-24bc-4bbb-e5c2-c380a67c42c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity\n",
       "GPE            386\n",
       "ORG            311\n",
       "PERSON         268\n",
       "CARDINAL       215\n",
       "DATE           123\n",
       "NORP            98\n",
       "LOC             90\n",
       "ORDINAL         18\n",
       "QUANTITY        16\n",
       "PRODUCT         15\n",
       "FAC             12\n",
       "WORK_OF_ART      9\n",
       "PERCENT          5\n",
       "LANGUAGE         4\n",
       "TIME             3\n",
       "MONEY            2\n",
       "EVENT            2\n",
       "LAW              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ner using spacy\n",
    "whole_text = \" \".join(DF[\"clean\"].to_list())\n",
    "spacy_ner_tagged = [(str(ent), ent.label_) for ent in nlp(whole_text).ents]\n",
    "DF_ner = pd.DataFrame(spacy_ner_tagged, columns = [\"token\", \"entity\"])\n",
    "DF_ner.head()\n",
    "\n",
    "DF_ner[\"entity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b116e422-dfe9-41e6-9b6b-0edcad499109",
   "metadata": {
    "id": "b116e422-dfe9-41e6-9b6b-0edcad499109"
   },
   "outputs": [],
   "source": [
    "# snorkel\n",
    "\n",
    "# create an empty spot to save the data\n",
    "stored_entities = []\n",
    "\n",
    "# first get the entities, must be two for relationship matches\n",
    "# create a function to grab the entities so we can use apply\n",
    "def get_entities(x):\n",
    "    \"\"\"\n",
    "    Grabs the names using spacy's entity labeler\n",
    "    \"\"\"\n",
    "    # get all the entities in this row\n",
    "    processed = nlp(x)\n",
    "\n",
    "    # get the tokens for each sentence\n",
    "    tokens = [word.text for word in processed]\n",
    "\n",
    "    # get all the entities\n",
    "    temp = [(str(ent), ent.label_) for ent in processed.ents if ent.label_ != \"\"]\n",
    "\n",
    "    # only move on if this row has at least two\n",
    "    if len(temp) > 1:\n",
    "        # finds all the combinations of pairs\n",
    "        temp2 = list(combinations(temp, 2))\n",
    "\n",
    "        # for each pair combination\n",
    "        for (entity1, entity2) in temp2:\n",
    "            # find the words for entity 1\n",
    "            entity1_words = [word.text for word in nlp(entity1[0])]\n",
    "            # find the token numbers for entity 1\n",
    "            entity1_ids = [i for i, val in enumerate(tokens) if val in entity1_words]\n",
    "\n",
    "            if len(entity1_words) > 1:\n",
    "                entity1_ids2 = tuple(idx for idx in entity1_ids[0:2])\n",
    "            else:\n",
    "                id_1 = [idx for idx in entity1_ids]\n",
    "                entity1_ids2 = (id_1[0], id_1[0])\n",
    "\n",
    "            # do the same thing with person 2\n",
    "            entity2_words = [word.text for word in nlp(entity2[0])]\n",
    "            entity2_ids = [i for i, val in enumerate(tokens) if val in entity2_words[0:2]]\n",
    "            if len(entity2_words) > 1:\n",
    "                entity2_ids2 = tuple(idx for idx in entity2_ids[0:2])\n",
    "            else:\n",
    "                id_2 = [idx for idx in entity2_ids]\n",
    "                entity2_ids2 = (id_2[0], id_2[0])\n",
    "\n",
    "            # store all this in a list\n",
    "            stored_entities.append(\n",
    "                [x, # original text\n",
    "                tokens, # tokens\n",
    "                entity1[0], # entity 1 name\n",
    "                entity2[0], # entity 2 name\n",
    "                entity1_ids2, # entity 1 id token tuple\n",
    "                entity2_ids2 # entity 2 id token tuple\n",
    "                ])\n",
    "\n",
    "#get_entities(\"Barbie and Ken went to the store, and Malibu bought a car.\")\n",
    "# list []\n",
    "# of tuples () with two items 0, 1\n",
    "# each of those tuples is a tuple of two items (), 0, 1\n",
    "# where 0 is the word/token, 1 is the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a01b7bb-b985-4dcc-9627-e87a3c97fa60",
   "metadata": {
    "id": "6a01b7bb-b985-4dcc-9627-e87a3c97fa60",
    "outputId": "dda864d6-c92e-4e52-c482-dd395a5878a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>entity1_word_idx</th>\n",
       "      <th>entity2_word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus, Valley, Civilisation, (, IVC, ), ...</td>\n",
       "      <td>The Indus Valley Civilisation</td>\n",
       "      <td>IVC</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(5, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus, Valley, Civilisation, (, IVC, ), ...</td>\n",
       "      <td>The Indus Valley Civilisation</td>\n",
       "      <td>the Indus Civilisation</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(1, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus, Valley, Civilisation, (, IVC, ), ...</td>\n",
       "      <td>The Indus Valley Civilisation</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(17, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus, Valley, Civilisation, (, IVC, ), ...</td>\n",
       "      <td>The Indus Valley Civilisation</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(25, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus, Valley, Civilisation, (, IVC, ), ...</td>\n",
       "      <td>The Indus Valley Civilisation</td>\n",
       "      <td>3300</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(30, 30)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1  The Indus Valley Civilisation (IVC), also know...   \n",
       "2  The Indus Valley Civilisation (IVC), also know...   \n",
       "3  The Indus Valley Civilisation (IVC), also know...   \n",
       "4  The Indus Valley Civilisation (IVC), also know...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, Indus, Valley, Civilisation, (, IVC, ), ...   \n",
       "1  [The, Indus, Valley, Civilisation, (, IVC, ), ...   \n",
       "2  [The, Indus, Valley, Civilisation, (, IVC, ), ...   \n",
       "3  [The, Indus, Valley, Civilisation, (, IVC, ), ...   \n",
       "4  [The, Indus, Valley, Civilisation, (, IVC, ), ...   \n",
       "\n",
       "                         entity1                 entity2 entity1_word_idx  \\\n",
       "0  The Indus Valley Civilisation                     IVC           (0, 1)   \n",
       "1  The Indus Valley Civilisation  the Indus Civilisation           (0, 1)   \n",
       "2  The Indus Valley Civilisation                  Bronze           (0, 1)   \n",
       "3  The Indus Valley Civilisation              South Asia           (0, 1)   \n",
       "4  The Indus Valley Civilisation                    3300           (0, 1)   \n",
       "\n",
       "  entity2_word_idx  \n",
       "0           (5, 5)  \n",
       "1          (1, 11)  \n",
       "2         (17, 17)  \n",
       "3         (25, 26)  \n",
       "4         (30, 30)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty spot to save the data\n",
    "stored_entities = []\n",
    "\n",
    "DF[\"clean\"].apply(get_entities)\n",
    "\n",
    "# create dataframe in snorkel structure\n",
    "DF_dev = pd.DataFrame(stored_entities,\n",
    "                      columns = [\"sentence\", \"tokens\", \"entity1\",\n",
    "                                 \"entity2\", \"entity1_word_idx\", \"entity2_word_idx\"])\n",
    "\n",
    "DF_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ae5f8d-5c7b-422e-ba6b-643df8dad258",
   "metadata": {
    "id": "b2ae5f8d-5c7b-422e-ba6b-643df8dad258"
   },
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# dictionary with label and pattern is the rules\n",
    "patterns = [{\"label\": \"LOC\",\n",
    "              \"pattern\": [{\"TEXT\": \"Indus\"},\n",
    "                          {\"TEXT\": \"Valley\"}, {\"TEXT\": \"Civilisation\"}]},\n",
    "             {\"label\": \"ORG\",\n",
    "              \"pattern\": [{\"TEXT\": \"East\"},\n",
    "                          {\"TEXT\": \"India\"}, {\"TEXT\": \"Company\"}]},\n",
    "             {\"label\": \"GPE\",\n",
    "              \"pattern\": [{\"TEXT\": \"Punjab\"}]},\n",
    "           {\"label\": \"GPE\",\n",
    "              \"pattern\": [{\"TEXT\": \"Multan\"}]}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff5c652-3bf2-42a2-b19d-099943500053",
   "metadata": {
    "id": "7ff5c652-3bf2-42a2-b19d-099943500053",
    "outputId": "70322cb4-3db8-4deb-e19a-d71e17f0349b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/spacy/displacy/__init__.py:69: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus Valley Civilisation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    IVC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "), also known as \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Indus Civilisation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", was a \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bronze\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " Age civilisation in the northwestern regions of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South Asia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", lasting from \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and in its mature form \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2600\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1900\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".  Together with ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egypt\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mesopotamia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", it was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " early civilisations of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Near East\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South Asia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", and of the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", the most widespread, its sites spanning an area from much of modern day \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", to some parts of northwestern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and northeast \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Afghanistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  The civilisation flourished both in the alluvial plain of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Indus River\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", which flows through the length of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and along a system of perennial monsoon-fed rivers that once coursed in the vicinity of the Ghaggar-Hakra, a seasonal river in northwest \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and eastern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  The term \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is sometimes applied to the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " civilisation after its type site \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " to be excavated early in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the 20th century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " in what was then the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Punjab\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " province of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    British\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and is now \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Punjab\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  The discovery of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and soon afterwards \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mohenjo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "-daro was the culmination of work that had begun after the founding of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Archaeological Survey of India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the British Raj\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1861\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".  There were earlier and later cultures called \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Early Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and Late Harappan in the same area. The early \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " cultures were populated from \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Neolithic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " cultures, the earliest and best-known of which is named after \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mehrgarh\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Balochistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " civilisation is sometimes called \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mature Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " to distinguish it from the earlier cultures</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole_text = \" \".join(DF[\"clean\"].to_list())\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "#ruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "ruler.add_patterns(patterns)\n",
    "doc = nlp(whole_text)\n",
    "\n",
    "from spacy import displacy\n",
    "displacy.render(doc[0:300], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0eba33-588c-418a-9e11-e760f5154892",
   "metadata": {
    "id": "ca0eba33-588c-418a-9e11-e760f5154892"
   },
   "source": [
    "#### Normalizing Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0864064e-9809-43b0-b7f2-8f1037ef3d6e",
   "metadata": {
    "id": "0864064e-9809-43b0-b7f2-8f1037ef3d6e"
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "from spacy import Language\n",
    "\n",
    "@Language.component(\"norm_entities\")\n",
    "def norm_entities(doc):\n",
    "    ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent[0].pos_ == \"DET\": # leading article\n",
    "            ent = Span(doc, ent.start+1, ent.end, label=ent.label)\n",
    "        if len(ent) > 0:\n",
    "            if ent[-1].pos_ == \"PART\": # trailing particle like 's\n",
    "                ent = Span(doc, ent.start, ent.end-1, label=ent.label)\n",
    "            ents.append(ent)\n",
    "    doc.ents = tuple(ents)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b784a71b-48fc-4899-84db-1c37d29f5386",
   "metadata": {
    "id": "b784a71b-48fc-4899-84db-1c37d29f5386",
    "outputId": "8af6b12e-52a8-4d3d-9719-6aed9ebbf266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Indus', 'Valley', 'Civilisation'], 'LOC')\n",
      "(['IVC'], 'ORG')\n",
      "(['Indus', 'Civilisation'], 'ORG')\n",
      "(['Bronze'], 'PERSON')\n",
      "(['South', 'Asia'], 'LOC')\n",
      "(['3300'], 'CARDINAL')\n",
      "(['BCE'], 'ORG')\n",
      "(['1300'], 'CARDINAL')\n",
      "(['BCE'], 'ORG')\n",
      "(['2600'], 'CARDINAL')\n",
      "(['BCE'], 'ORG')\n",
      "(['1900'], 'CARDINAL')\n",
      "(['BCE'], 'ORG')\n",
      "(['Egypt'], 'GPE')\n",
      "(['Mesopotamia'], 'GPE')\n",
      "(['one'], 'CARDINAL')\n",
      "(['three'], 'CARDINAL')\n",
      "(['Near', 'East'], 'LOC')\n",
      "(['South', 'Asia'], 'LOC')\n",
      "(['three'], 'CARDINAL')\n",
      "(['Pakistan'], 'GPE')\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe('norm_entities')\n",
    "doc = nlp(whole_text)\n",
    "print(*[([t.text for t in e], e.label_) for e in doc[0:100].ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedd5c7-5e50-4c23-8fd1-27863e5ccff6",
   "metadata": {
    "id": "ccedd5c7-5e50-4c23-8fd1-27863e5ccff6"
   },
   "source": [
    "#### Merging Entity Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d90c28e-0a79-4d86-8697-5cac03999223",
   "metadata": {
    "id": "1d90c28e-0a79-4d86-8697-5cac03999223",
    "outputId": "f6a83106-e114-4f41-e521-27177a4ef898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Indus Valley Civilisation', 'LOC') ('IVC', 'ORG') ('Indus Civilisation', 'ORG') ('Bronze', 'PERSON') ('South Asia', 'LOC') ('3300', 'CARDINAL') ('BCE', 'ORG') ('1300', 'CARDINAL') ('BCE', 'ORG') ('2600', 'CARDINAL') ('BCE', 'ORG') ('1900', 'CARDINAL') ('BCE', 'ORG') ('Egypt', 'GPE') ('Mesopotamia', 'GPE') ('one', 'CARDINAL') ('three', 'CARDINAL') ('Near East', 'LOC') ('South Asia', 'LOC') ('three', 'CARDINAL') ('Pakistan', 'GPE') ('India', 'GPE') ('Afghanistan', 'GPE')\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import merge_entities\n",
    "if nlp.has_pipe('merge_entities'): ###\n",
    "    _ = nlp.remove_pipe('merge_entities') ###\n",
    "nlp.add_pipe('merge_entities')\n",
    "\n",
    "doc = nlp(whole_text)\n",
    "print(*[(t.text, t.ent_type_) for t in doc[0:100] if t.ent_type_ != ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46150d6a-3964-4975-bfb4-c729cae92633",
   "metadata": {
    "id": "46150d6a-3964-4975-bfb4-c729cae92633"
   },
   "source": [
    "#### Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b57cb2ab-4e3f-4c70-89ba-eed390a9abe7",
   "metadata": {
    "id": "b57cb2ab-4e3f-4c70-89ba-eed390a9abe7",
    "outputId": "a3e8fa11-fe62-4570-9192-21b228f59bb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.init_coref(doc)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not in book, but useful if you modify the extension\n",
    "from spacy.tokens import Token\n",
    "\n",
    "if Token.has_extension('ref_n'):\n",
    "    _ = Token.remove_extension('ref_n')\n",
    "if Token.has_extension('ref_t'):\n",
    "    _ = Token.remove_extension('ref_t')\n",
    "if Token.has_extension('ref_t_'):\n",
    "    _ = Token.remove_extension('ref_t_')\n",
    "\n",
    "from spacy.tokens import Token\n",
    "Token.set_extension('ref_n', default='') #ref name\n",
    "Token.set_extension('ref_t', default='') #ref type\n",
    "\n",
    "@Language.component(\"init_coref\")\n",
    "def init_coref(doc):\n",
    "    for e in doc.ents:\n",
    "        if e.label_ in ['LOC', 'ORG', 'GPE']:\n",
    "            e[0]._.ref_n, e[0]._.ref_t = e.text, e.label_\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"init_coref\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027aa4d7-3c1d-4cb3-a0c4-dd052603711b",
   "metadata": {
    "id": "027aa4d7-3c1d-4cb3-a0c4-dd052603711b"
   },
   "source": [
    "#### Alias Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "530036b4-818e-434a-ba23-731413e3d7a7",
   "metadata": {
    "id": "530036b4-818e-434a-ba23-731413e3d7a7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "def display_ner(doc, include_punct=False):\n",
    "    \"\"\"Generate data frame for visualization of spaCy doc with custom attributes.\"\"\"\n",
    "\n",
    "    rows = []\n",
    "    for i, t in enumerate(doc):\n",
    "        if not t.is_punct or include_punct:\n",
    "            row = {'token': i,\n",
    "                   'text': t.text, 'lemma': t.lemma_,\n",
    "                   'pos': t.pos_, 'dep': t.dep_, 'ent_type': t.ent_type_,\n",
    "                   'ent_iob_': t.ent_iob_}\n",
    "\n",
    "            if doc.has_extension('has_coref'):\n",
    "                if doc._.coref_clusters is not None and \\\n",
    "                   t.has_extension('in_coref') and t._.in_coref: # neuralcoref attributes\n",
    "                    row['in_coref'] = t._.in_coref\n",
    "                    row['main_coref'] = t._.coref_clusters[0].main.text\n",
    "                else:\n",
    "                    row['in_coref'] = None\n",
    "                    row['main_coref'] = None\n",
    "            if t.has_extension('ref_n'): # referent attribute\n",
    "                row['ref_n'] = t._.ref_n\n",
    "                row['ref_t'] = t._.ref_t\n",
    "            if t.has_extension('ref_ent'): # ref_n/ref_t\n",
    "                row['ref_ent'] = t._.ref_ent\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).set_index('token')\n",
    "    df.index.name = None\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_dep_tree(doc, skip_punct=True):\n",
    "    \"\"\"Utility function to pretty print the dependency tree.\"\"\"\n",
    "\n",
    "    def print_recursive(root, indent, skip_punct):\n",
    "        if not root.dep_ == 'punct' or not skip_punct:\n",
    "            print(\" \"*indent + f\"{root} [{root.pos_}, {root.dep_}]\")\n",
    "        for left in root.lefts:\n",
    "            print_recursive(left, indent=indent+4, skip_punct=skip_punct)\n",
    "        for right in root.rights:\n",
    "            print_recursive(right, indent=indent+4, skip_punct=skip_punct)\n",
    "\n",
    "    for sent in doc.sents: # iterate over all sentences in a doc\n",
    "        print_recursive(sent.root, indent=0, skip_punct=skip_punct)\n",
    "\n",
    "\n",
    "# acronyms created after cooccurrence analysis\n",
    "_acronyms = {\n",
    "    'IVC': 'Indus Valley Civilisation',\n",
    "    'ASI': 'Archaeological Survey of India',\n",
    "    'HARP': 'Harappa Archaeological Research Project '\n",
    "}\n",
    "\n",
    "# add acronyms (all acronyms are organizations)\n",
    "alias_lookup = {acro: (text, 'ORG') for (acro, text) in _acronyms.items()}\n",
    "\n",
    "alias_lookup['IVC'] = ('Indus Valley Civilisation', 'LOC')\n",
    "\n",
    "alias_list = {('Indus Valley Civilisation', 'LOC'):\n",
    "                ['The Indus Valley Civilisation']\n",
    "}\n",
    "\n",
    "# invert alias_list; overwrites entries in acronyms like DOT\n",
    "alias_lookup.update({alias: ent for (ent, aliases) in alias_list.items()\n",
    "                                for alias in aliases})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bea3146-64a3-4fcb-9606-9459c704b542",
   "metadata": {
    "id": "4bea3146-64a3-4fcb-9606-9459c704b542",
    "outputId": "9c42f4d9-33ef-41d1-fe0c-fe19f1878566"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>ref_n</th>\n",
       "      <th>ref_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IVC</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indus Civilisation</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Indus Civilisation</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>South Asia</td>\n",
       "      <td>LOC</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCE</td>\n",
       "      <td>ORG</td>\n",
       "      <td>BCE</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13014</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13020</th>\n",
       "      <td>Cemetery H</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Cemetery H</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13033</th>\n",
       "      <td>Hinduism</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13047</th>\n",
       "      <td>Indus</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Indus</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text ent_type                      ref_n ref_t\n",
       "1      Indus Valley Civilisation      LOC  Indus Valley Civilisation   LOC\n",
       "3                            IVC      LOC  Indus Valley Civilisation   LOC\n",
       "10            Indus Civilisation      ORG         Indus Civilisation   ORG\n",
       "22                    South Asia      LOC                 South Asia   LOC\n",
       "28                           BCE      ORG                        BCE   ORG\n",
       "...                          ...      ...                        ...   ...\n",
       "13014                  Rajasthan      GPE                  Rajasthan   GPE\n",
       "13020                 Cemetery H      ORG                 Cemetery H   ORG\n",
       "13033                   Hinduism      GPE                   Hinduism   GPE\n",
       "13040  Indus Valley Civilisation      LOC  Indus Valley Civilisation   LOC\n",
       "13047                      Indus      GPE                      Indus   GPE\n",
       "\n",
       "[801 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.component(\"propagate_ent_type\")\n",
    "def propagate_ent_type(doc):\n",
    "    \"\"\"propagate entity type stored in ref_t\"\"\"\n",
    "    ents = []\n",
    "    for e in doc.ents:\n",
    "        if e[0]._.ref_n != '': # if e is a coreference\n",
    "            e = Span(doc, e.start, e.end, label=e[0]._.ref_t)\n",
    "        ents.append(e)\n",
    "    doc.ents = tuple(ents)\n",
    "    return doc\n",
    "\n",
    "@Language.component(\"alias_resolver\")\n",
    "def alias_resolver(doc):\n",
    "    \"\"\"Lookup aliases and store result in ref_t, ref_n\"\"\"\n",
    "    for ent in doc.ents:\n",
    "        token = ent[0].text\n",
    "        if token in alias_lookup:\n",
    "            a_name, a_type = alias_lookup[token]\n",
    "            ent[0]._.ref_n, ent[0]._.ref_t = a_name, a_type\n",
    "    return propagate_ent_type(doc)\n",
    "\n",
    "nlp.add_pipe('alias_resolver')\n",
    "\n",
    "doc = nlp(whole_text)\n",
    "display_ner(doc).query(\"ref_n != ''\")[['text', 'ent_type', 'ref_n', 'ref_t']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd79c5-a96b-4552-92d0-871160d9f8c7",
   "metadata": {
    "id": "32cd79c5-a96b-4552-92d0-871160d9f8c7"
   },
   "source": [
    "#### Resolving Name Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1590abf0-ce88-4616-9ef6-80eb32c7a126",
   "metadata": {
    "id": "1590abf0-ce88-4616-9ef6-80eb32c7a126",
    "outputId": "1439ba16-0082-429c-8916-94396881e7fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/spacy/displacy/__init__.py:69: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus Valley Civilisation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    IVC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "), also known as the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus Civilisation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", was a \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bronze\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " Age civilisation in the northwestern regions of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South Asia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", lasting from \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1300\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and in its mature form \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2600\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1900\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BCE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".  Together with ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egypt\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mesopotamia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", it was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " early civilisations of the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Near East\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South Asia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", and of the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", the most widespread, its sites spanning an area from much of modern day \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", to some parts of northwestern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and northeast \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Afghanistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  The civilisation flourished both in the alluvial plain of the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus River\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", which flows through the length of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and along a system of perennial monsoon-fed rivers that once coursed in the vicinity of the Ghaggar-Hakra, a seasonal river in northwest \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and eastern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  The term \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is sometimes applied to the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " civilisation after its type site \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " to be excavated early in the \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    20th century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " in what was then the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Punjab\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " province of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    British\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and is now \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Punjab\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  The discovery of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and soon afterwards \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mohenjo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "-daro was the culmination of work that had begun after the founding of the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Archaeological Survey of India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    British Raj\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1861\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".  There were earlier and later cultures called \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Early Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and Late Harappan in the same area. The early \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " cultures were populated from \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Neolithic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " cultures, the earliest and best-known of which is named after \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mehrgarh\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Balochistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pakistan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " civilisation is sometimes called \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mature Harappan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " to distinguish it from the earlier cultures. The cities of the ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " were noted for their urban planning, baked </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def name_match(m1, m2):\n",
    "    m2 = re.sub(r'[()\\.]', '', m2) # ignore parentheses and dots\n",
    "    m2 = r'\\b' + m2 + r'\\b' # \\b marks word boundary\n",
    "    m2 = re.sub(r'\\s+', r'\\\\b.*\\\\b', m2)\n",
    "    return re.search(m2, m1, flags=re.I) is not None\n",
    "\n",
    "@Language.component(\"name_resolver\")\n",
    "def name_resolver(doc):\n",
    "    \"\"\"create name-based reference to e1 as primary mention of e2\"\"\"\n",
    "    ents = [e for e in doc.ents if e.label_ in ['ORG', 'PERSON']]\n",
    "    for i, e1 in enumerate(ents):\n",
    "        for e2 in ents[i+1:]:\n",
    "            if name_match(e1[0]._.ref_n, e2[0].text):\n",
    "                e2[0]._.ref_n = e1[0]._.ref_n\n",
    "                e2[0]._.ref_t = e1[0]._.ref_t\n",
    "    return propagate_ent_type(doc)\n",
    "\n",
    "nlp.add_pipe('name_resolver')\n",
    "\n",
    "doc = nlp(whole_text)\n",
    "displacy.render(doc[0:300], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2d762-cb38-41a7-bc74-1efde477ee9e",
   "metadata": {
    "id": "aed2d762-cb38-41a7-bc74-1efde477ee9e"
   },
   "source": [
    "#### Name Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f00099a7-8d90-4c48-aaf1-4c2bfebc6332",
   "metadata": {
    "id": "f00099a7-8d90-4c48-aaf1-4c2bfebc6332",
    "outputId": "aa85cfa5-efbd-4e34-ed3c-7988936f289c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hughes Tool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.norm_names(doc)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_legal_suffix(text):\n",
    "    return re.sub(r'(\\s+and)?(\\s+|\\b(Co|Corp|Inc|Plc|Ltd)\\b\\.?)*$', '', text)\n",
    "\n",
    "print(strip_legal_suffix('Hughes Tool Co'))\n",
    "\n",
    "@Language.component(\"norm_names\")\n",
    "def norm_names(doc):\n",
    "    for t in doc:\n",
    "        if t._.ref_n != '' and t._.ref_t in ['ORG']:\n",
    "            t._.ref_n = strip_legal_suffix(t._.ref_n)\n",
    "            if t._.ref_n == '':\n",
    "                t._.ref_t = ''\n",
    "\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"norm_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af6400d-01a0-4e7c-9424-7f09c9df2a65",
   "metadata": {
    "id": "4af6400d-01a0-4e7c-9424-7f09c9df2a65"
   },
   "outputs": [],
   "source": [
    "# create an empty spot to save the data\n",
    "stored_entities = []\n",
    "\n",
    "DF[\"clean\"].apply(get_entities)\n",
    "\n",
    "# create dataframe in snorkel structure\n",
    "DF_dev_master = pd.DataFrame(stored_entities,\n",
    "                      columns = [\"sentence\", \"tokens\", \"entity1\",\n",
    "                                 \"entity2\", \"entity1_word_idx\", \"entity2_word_idx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb7a236e-8c54-4688-bad3-f23027537626",
   "metadata": {
    "id": "eb7a236e-8c54-4688-bad3-f23027537626",
    "outputId": "90258a79-e98f-4029-e45e-3e493af1c02e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>entity1_word_idx</th>\n",
       "      <th>entity2_word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>IVC</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(3, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>Indus Civilisation</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(14, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(22, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>3300</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(26, 26)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1  The Indus Valley Civilisation (IVC), also know...   \n",
       "2  The Indus Valley Civilisation (IVC), also know...   \n",
       "3  The Indus Valley Civilisation (IVC), also know...   \n",
       "4  The Indus Valley Civilisation (IVC), also know...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "1  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "2  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "3  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "4  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "\n",
       "                     entity1             entity2 entity1_word_idx  \\\n",
       "0  Indus Valley Civilisation                 IVC           (1, 1)   \n",
       "1  Indus Valley Civilisation  Indus Civilisation           (1, 1)   \n",
       "2  Indus Valley Civilisation              Bronze           (1, 1)   \n",
       "3  Indus Valley Civilisation          South Asia           (1, 1)   \n",
       "4  Indus Valley Civilisation                3300           (1, 1)   \n",
       "\n",
       "  entity2_word_idx  \n",
       "0           (3, 3)  \n",
       "1               ()  \n",
       "2         (14, 14)  \n",
       "3         (22, 22)  \n",
       "4         (26, 26)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_dev_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "139fc137-e0fd-4248-b815-3f4130b2f912",
   "metadata": {
    "id": "139fc137-e0fd-4248-b815-3f4130b2f912",
    "outputId": "ae9bfe9d-5b34-4b1a-b143-7213132c6572"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>entity1_word_idx</th>\n",
       "      <th>entity2_word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>IVC</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(3, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>Indus Civilisation</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(14, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(22, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>3300</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(26, 26)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1  The Indus Valley Civilisation (IVC), also know...   \n",
       "2  The Indus Valley Civilisation (IVC), also know...   \n",
       "3  The Indus Valley Civilisation (IVC), also know...   \n",
       "4  The Indus Valley Civilisation (IVC), also know...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "1  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "2  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "3  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "4  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "\n",
       "                     entity1             entity2 entity1_word_idx  \\\n",
       "0  Indus Valley Civilisation                 IVC           (1, 1)   \n",
       "1  Indus Valley Civilisation  Indus Civilisation           (1, 1)   \n",
       "2  Indus Valley Civilisation              Bronze           (1, 1)   \n",
       "3  Indus Valley Civilisation          South Asia           (1, 1)   \n",
       "4  Indus Valley Civilisation                3300           (1, 1)   \n",
       "\n",
       "  entity2_word_idx  \n",
       "0           (3, 3)  \n",
       "1               ()  \n",
       "2         (14, 14)  \n",
       "3         (22, 22)  \n",
       "4         (26, 26)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset of main dataset for better visualization\n",
    "DF_dev = DF_dev_master[0000:6000]\n",
    "DF_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27512af-bab2-4386-867b-21bfafb967ad",
   "metadata": {
    "id": "f27512af-bab2-4386-867b-21bfafb967ad",
    "outputId": "36eb9f94-7990-4ee2-db22-cb5ff3e406a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>entity1_word_idx</th>\n",
       "      <th>entity2_word_idx</th>\n",
       "      <th>too_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>IVC</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(14, 14)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(22, 22)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>3300</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(26, 26)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>BCE</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "2  The Indus Valley Civilisation (IVC), also know...   \n",
       "3  The Indus Valley Civilisation (IVC), also know...   \n",
       "4  The Indus Valley Civilisation (IVC), also know...   \n",
       "5  The Indus Valley Civilisation (IVC), also know...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "2  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "3  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "4  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "5  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "\n",
       "                     entity1     entity2 entity1_word_idx entity2_word_idx  \\\n",
       "0  Indus Valley Civilisation         IVC           (1, 1)           (3, 3)   \n",
       "2  Indus Valley Civilisation      Bronze           (1, 1)         (14, 14)   \n",
       "3  Indus Valley Civilisation  South Asia           (1, 1)         (22, 22)   \n",
       "4  Indus Valley Civilisation        3300           (1, 1)         (26, 26)   \n",
       "5  Indus Valley Civilisation         BCE           (1, 1)         (28, 28)   \n",
       "\n",
       "   too_small  \n",
       "0          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  \n",
       "5          4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude matches\n",
    "DF_dev = DF_dev[DF_dev[\"entity1\"] != DF_dev[\"entity2\"]]\n",
    "\n",
    "# exclude empties due to spacy misprocessing\n",
    "DF_dev['too_small'] = DF_dev['entity1_word_idx'].apply(len) + DF_dev['entity2_word_idx'].apply(len)\n",
    "\n",
    "DF_dev = DF_dev[DF_dev['too_small'] == 4]\n",
    "\n",
    "DF_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f85c3a79-f031-4b8f-8c88-d709821fe397",
   "metadata": {
    "id": "f85c3a79-f031-4b8f-8c88-d709821fe397"
   },
   "outputs": [],
   "source": [
    "# get words between the data points\n",
    "@preprocessor()\n",
    "def get_text_between(cand: DataPoint) -> DataPoint:\n",
    "    \"\"\"\n",
    "    Returns the text between the two person mentions in the sentence\n",
    "    \"\"\"\n",
    "    start = cand.entity1_word_idx[1] + 1\n",
    "    end = cand.entity2_word_idx[0]\n",
    "    cand.between_tokens = cand.tokens[start:end]\n",
    "    return cand\n",
    "\n",
    "# get words next to the data points\n",
    "@preprocessor()\n",
    "def get_left_tokens(cand: DataPoint) -> DataPoint:\n",
    "    \"\"\"\n",
    "    Returns tokens in the length 5 window to the left of the person mentions\n",
    "    \"\"\"\n",
    "    # TODO: need to pass window as input params\n",
    "    window = 5\n",
    "\n",
    "    end = cand.entity1_word_idx[0]\n",
    "    cand.entity1_left_tokens = cand.tokens[0:end][-1 - window : -1]\n",
    "\n",
    "    end = cand.entity2_word_idx[0]\n",
    "    cand.entity2_left_tokens = cand.tokens[0:end][-1 - window : -1]\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad2d65b-c71e-4487-b951-b1585fc468ec",
   "metadata": {
    "id": "0ad2d65b-c71e-4487-b951-b1585fc468ec"
   },
   "outputs": [],
   "source": [
    "# make this part up with words that are clues\n",
    "friend = {\"River\", \"!\", \"language\", \"veda\", \"Sanskrit\", \"Indus\",\n",
    "          \"and\"}\n",
    "\n",
    "# this part important\n",
    "is_friend = 1\n",
    "not_friend = 0\n",
    "\n",
    "@labeling_function(resources=dict(friend=friend), pre=[get_text_between])\n",
    "def between_friend(x,friend):\n",
    "    return is_friend if len(friend.intersection(set(x.between_tokens))) > 0 else not_friend\n",
    "\n",
    "@labeling_function(resources=dict(friend=friend), pre=[get_left_tokens])\n",
    "def left_friend(x,friend):\n",
    "    if len(friend.intersection(set(x.entity1_left_tokens))) > 0:\n",
    "        return is_friend\n",
    "    elif len(friend.intersection(set(x.entity2_left_tokens))) > 0:\n",
    "        return is_friend\n",
    "    else:\n",
    "        return not_friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31584a83-6be4-437d-b03e-77b883fdb64b",
   "metadata": {
    "id": "31584a83-6be4-437d-b03e-77b883fdb64b",
    "outputId": "96cba60b-7b1a-4e29-a460-99c822834b9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5521/5521 [00:01<00:00, 3052.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of functions to run\n",
    "# lfs labeling functions\n",
    "lfs = [\n",
    "    between_friend,\n",
    "    left_friend\n",
    "]\n",
    "# build the applier function\n",
    "applier = PandasLFApplier(lfs)\n",
    "# run it on the dataset\n",
    "L_dev = applier.apply(DF_dev)\n",
    "L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e8b0d11-5028-49e0-8bba-38cbe49beab3",
   "metadata": {
    "id": "9e8b0d11-5028-49e0-8bba-38cbe49beab3",
    "outputId": "8ee4ddf3-8c49-4d60-eace-cbebbf527722"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>entity1_word_idx</th>\n",
       "      <th>entity2_word_idx</th>\n",
       "      <th>too_small</th>\n",
       "      <th>between_friend</th>\n",
       "      <th>left_friend</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>IVC</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(14, 14)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(22, 22)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>3300</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(26, 26)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>BCE</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "2  The Indus Valley Civilisation (IVC), also know...   \n",
       "3  The Indus Valley Civilisation (IVC), also know...   \n",
       "4  The Indus Valley Civilisation (IVC), also know...   \n",
       "5  The Indus Valley Civilisation (IVC), also know...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "2  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "3  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "4  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "5  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "\n",
       "                     entity1     entity2 entity1_word_idx entity2_word_idx  \\\n",
       "0  Indus Valley Civilisation         IVC           (1, 1)           (3, 3)   \n",
       "2  Indus Valley Civilisation      Bronze           (1, 1)         (14, 14)   \n",
       "3  Indus Valley Civilisation  South Asia           (1, 1)         (22, 22)   \n",
       "4  Indus Valley Civilisation        3300           (1, 1)         (26, 26)   \n",
       "5  Indus Valley Civilisation         BCE           (1, 1)         (28, 28)   \n",
       "\n",
       "   too_small  between_friend  left_friend  friend  \n",
       "0        4.0             0.0          0.0     0.0  \n",
       "2        4.0             0.0          0.0     0.0  \n",
       "3        4.0             0.0          0.0     0.0  \n",
       "4        4.0             0.0          0.0     0.0  \n",
       "5        4.0             0.0          0.0     0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev = pd.DataFrame(L_dev, columns = [\"between_friend\", \"left_friend\"])\n",
    "L_dev\n",
    "\n",
    "DF_combo = pd.concat([DF_dev, L_dev], axis = 1) #axis = 1 by column\n",
    "DF_combo[\"friend\"] = DF_combo[\"left_friend\"] + DF_combo[\"between_friend\"]\n",
    "DF_combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f2e94eb-06b5-4972-aec2-952c53be2e39",
   "metadata": {
    "id": "7f2e94eb-06b5-4972-aec2-952c53be2e39",
    "outputId": "c07824bb-faf9-49d4-f3bc-be0b7216178f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>entity1</th>\n",
       "      <th>entity2</th>\n",
       "      <th>entity1_word_idx</th>\n",
       "      <th>entity2_word_idx</th>\n",
       "      <th>too_small</th>\n",
       "      <th>between_friend</th>\n",
       "      <th>left_friend</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>BCE</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Indus Valley Civilisation</td>\n",
       "      <td>BCE</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(28, 28)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>IVC</td>\n",
       "      <td>1300</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(30, 30)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>IVC</td>\n",
       "      <td>2600</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>(39, 39)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>[The, Indus Valley Civilisation, (, IVC, ), ,,...</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>3300</td>\n",
       "      <td>(14, 14)</td>\n",
       "      <td>(26, 26)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "7   The Indus Valley Civilisation (IVC), also know...   \n",
       "9   The Indus Valley Civilisation (IVC), also know...   \n",
       "17  The Indus Valley Civilisation (IVC), also know...   \n",
       "19  The Indus Valley Civilisation (IVC), also know...   \n",
       "34  The Indus Valley Civilisation (IVC), also know...   \n",
       "\n",
       "                                               tokens  \\\n",
       "7   [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "9   [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "17  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "19  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "34  [The, Indus Valley Civilisation, (, IVC, ), ,,...   \n",
       "\n",
       "                      entity1 entity2 entity1_word_idx entity2_word_idx  \\\n",
       "7   Indus Valley Civilisation     BCE           (1, 1)         (28, 28)   \n",
       "9   Indus Valley Civilisation     BCE           (1, 1)         (28, 28)   \n",
       "17                        IVC    1300           (3, 3)         (30, 30)   \n",
       "19                        IVC    2600           (3, 3)         (39, 39)   \n",
       "34                     Bronze    3300         (14, 14)         (26, 26)   \n",
       "\n",
       "    too_small  between_friend  left_friend  friend  \n",
       "7         4.0             1.0          1.0     2.0  \n",
       "9         4.0             1.0          0.0     1.0  \n",
       "17        4.0             1.0          1.0     2.0  \n",
       "19        4.0             1.0          0.0     1.0  \n",
       "34        4.0             1.0          1.0     2.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_combo.query(\"friend !=0\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82665558-cf95-4e01-8dde-a939b1e5b5f0",
   "metadata": {
    "id": "82665558-cf95-4e01-8dde-a939b1e5b5f0",
    "outputId": "df3cfe71-3482-4583-d4d3-519ab1605d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 10)\n",
      "(1348, 10)\n"
     ]
    }
   ],
   "source": [
    "# entities cannot be equal\n",
    "DF_combo = DF_combo[DF_combo[\"entity1\"] != DF_combo[\"entity2\"]]\n",
    "\n",
    "# only our friend options\n",
    "DF_friend = DF_combo[DF_combo[\"friend\"] > 0]\n",
    "\n",
    "# only our not friend options\n",
    "DF_not = DF_combo[DF_combo[\"friend\"] == 0]\n",
    "\n",
    "print(DF_friend.shape)\n",
    "print(DF_not.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f4041-38d1-41b8-bcc0-e299c8dbdff4",
   "metadata": {
    "id": "1a4f4041-38d1-41b8-bcc0-e299c8dbdff4"
   },
   "source": [
    "#### NER Summary\n",
    "\n",
    "**&nbsp;1. What kinds of relationships did I explore? Did I find any?**\n",
    "\n",
    "The NER focused on identifying and analyzing connections between named entities such as locations, people, organizations, and specific cultural or historical references, exploring possible relational links between the entities, and specifically addressing cultural and historical elements within a broader context. Here are some specific examples and findings:\n",
    "\n",
    "**&nbsp;1. Geographical and Historical Relationships:** The analysis highlighted relationships involving geographical entities like \"Indus Valley\" and historical periods or cultural entities like \"Harappan Culture.\" This suggests an emphasis on understanding the spatial and cultural-historical context of the entities discussed.\n",
    "\n",
    "**&nbsp;2. Organizational Relationships:** Entities such as \"ASI\" (Archaeological Survey of India) and \"HARP\" (Harappa Archaeological Research Project) were linked, indicating explorations of how various research organizations interact with or relate to historical sites and projects.\n",
    "\n",
    "**&nbsp;3. Cultural Connections:** This included exploring relationships between different cultural phases, such as \"Early Harappan culture\" and \"Late Harappan culture,\" which provided insights into the continuity or evolution within the civilization.\n",
    "\n",
    "**&nbsp;4. Alias and Coreference Resolutions:** Different names referring to the same entity are identified, such as \"Indus Valley Civilisation\" being referred to simply as \"Indus\" in some contexts. This is crucial for consolidating data points and understanding entity relationships comprehensively.\n",
    "\n",
    "These analyses collectively aimed to enhance the understanding of the Indus Valley Civilisation by mapping out the interconnections between its various cultural, geographical, and institutional aspects. The application of named entity recognition (NER) and subsequent relational analysis provided a structured way to approach complex historical data, making it more accessible for educational and research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5524d75-6521-4387-8c14-6977121e9dee",
   "metadata": {
    "id": "f5524d75-6521-4387-8c14-6977121e9dee"
   },
   "source": [
    "### Information Extraction Summary\n",
    "\n",
    "**&nbsp;1. Summarizing the results from the information extraction section.**\n",
    "\n",
    "The information extraction process showcased detailed text analysis, extracting and interpreting a rich array of entities and relationships, each providing a layer of analysis that contributed to a deeper understanding of the text.\n",
    "\n",
    "**Key Learnings and Results:**\n",
    "- **Keyphrase Extraction:** From the \"KPE\", phrases such as _\"mature Harappan culture\"_ and _\"Indus River Valley site\"_ were highlighted. This helped identify the main themes and topics, as the `Indus Valley civilization`, indicating the text's central focus areas.\n",
    "- **Entities Identified:** Various entities like _\"Indus Valley Civilisation\"_ and _\"Harappan Culture\"_ were identified, signifying the text's key historical and cultural subjects. It was further expanded by detecting relationships like geographical connections between _\"Rajasthan\"_ and _\"Gangetic Plain\"_, showing the spatial spread of cultural influences.\n",
    "- **Relationships Explored**: Relationships between these entities were extensively analyzed. For instance, geographical and organizational relationships were uncovered through NER and further validated or hypothesized using Snorkel, which employed labeling functions to suggest potential connections based on context and proximity.\n",
    "For example, potential historical connections between _\"Cemetery H culture\"_ and _\"Ochre Coloured Pottery culture\"_ were examined, indicating how cultural practices might have spread or evolved.\n",
    "\n",
    "However, despite these successes, there were gaps in the extraction where spaCy's general model failed to recognize certain specialized terms specific to the Indus Valley Civilization, such as particular cultural artifacts or less commonly referenced archaeological terms. This limitation suggests a potential improvement where training a custom model on a domain-specific corpus could enhance accuracy and comprehensiveness. Such a model could be trained on archaeological texts or databases to capture better the unique nomenclature and entities associated with historical and cultural studies. Expanding the scope of information extraction, techniques like relation extraction could also be employed to identify and understand the relationships between the extracted entities, such as the interactions between different cultural sites or the influence of specific historical figures on various events. To make information extraction easier and more accessible, we have the power to develop more interactive and user-friendly annotation tools for training data. These tools can put the control in our hands, allowing us to fine-tune the models to our specific needs. Integrating machine learning models with feedback loops where they learn from corrections and additions made by users could greatly enhance their learning efficiency and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949ea14-fb48-4a34-8ec9-4f947333d326",
   "metadata": {
    "id": "9949ea14-fb48-4a34-8ec9-4f947333d326"
   },
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5465e3a8-f580-4595-af88-3e37a8faddb5",
   "metadata": {
    "id": "5465e3a8-f580-4595-af88-3e37a8faddb5"
   },
   "outputs": [],
   "source": [
    "# define a search\n",
    "def search(query, model, text_list):\n",
    "\n",
    "    t=time.time()\n",
    "    query_vector = model.encode([query])\n",
    "    k = 5\n",
    "    top_k = index.search(query_vector, k)\n",
    "    print('totaltime: {}'.format(time.time()-t))\n",
    "    return [text_list[_id] for _id in top_k[1].tolist()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "691c8aea-6a8f-49b1-9ae3-774b010780dd",
   "metadata": {
    "id": "691c8aea-6a8f-49b1-9ae3-774b010780dd"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "def print_rouge_score(rouge_score):\n",
    "    for k,v in rouge_score.items():\n",
    "        print (k, 'Precision:', \"{:.2f}\".format(v.precision), 'Recall:', \"{:.2f}\".format(v.recall), 'fmeasure:', \"{:.2f}\".format(v.fmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae9b5a46-6f57-4f9f-956e-0169699a4be2",
   "metadata": {
    "id": "ae9b5a46-6f57-4f9f-956e-0169699a4be2"
   },
   "outputs": [],
   "source": [
    "# Function to process text\n",
    "def process_text2(text):\n",
    "    words = word_tokenize(text)\n",
    "    #words = [word for word in words if word.isalnum()]  # Remove punctuation\n",
    "    #words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    #words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatize\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8050fd78-5318-4f66-a415-3801bf1ccd42",
   "metadata": {
    "id": "8050fd78-5318-4f66-a415-3801bf1ccd42",
    "outputId": "afa6b57d-ffcd-4c4c-bd39-0562eea3f7be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation[1] (IVC), also k...</td>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>The Indus Valley Civilisation ( IVC ) , also k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2][a] Together with ancient Egypt and Mesopot...</td>\n",
       "      <td>Together with ancient Egypt and Mesopotamia, ...</td>\n",
       "      <td>Together with ancient Egypt and Mesopotamia , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3][b] The civilisation flourished both in the...</td>\n",
       "      <td>The civilisation flourished both in the alluv...</td>\n",
       "      <td>The civilisation flourished both in the alluvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2][4]\\nThe term Harappan is sometimes applied...</td>\n",
       "      <td>The term Harappan is sometimes applied to the...</td>\n",
       "      <td>The term Harappan is sometimes applied to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5][c] The discovery of Harappa and soon after...</td>\n",
       "      <td>The discovery of Harappa and soon afterwards ...</td>\n",
       "      <td>The discovery of Harappa and soon afterwards M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Indus Valley Civilisation[1] (IVC), also k...   \n",
       "1  [2][a] Together with ancient Egypt and Mesopot...   \n",
       "2  [3][b] The civilisation flourished both in the...   \n",
       "3  [2][4]\\nThe term Harappan is sometimes applied...   \n",
       "4  [5][c] The discovery of Harappa and soon after...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1   Together with ancient Egypt and Mesopotamia, ...   \n",
       "2   The civilisation flourished both in the alluv...   \n",
       "3   The term Harappan is sometimes applied to the...   \n",
       "4   The discovery of Harappa and soon afterwards ...   \n",
       "\n",
       "                                           processed  \n",
       "0  The Indus Valley Civilisation ( IVC ) , also k...  \n",
       "1  Together with ancient Egypt and Mesopotamia , ...  \n",
       "2  The civilisation flourished both in the alluvi...  \n",
       "3  The term Harappan is sometimes applied to the ...  \n",
       "4  The discovery of Harappa and soon afterwards M...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning\n",
    "DF_new[\"clean\"] = DF_new[\"text\"].apply(clean_up)\n",
    "DF_new[\"processed\"] = DF_new[\"clean\"].apply(process_text2)\n",
    "DF_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d0a50-8bce-47f2-a5fb-f9f1bcbce7fa",
   "metadata": {
    "id": "a57d0a50-8bce-47f2-a5fb-f9f1bcbce7fa"
   },
   "source": [
    "### Search Engine\n",
    "\n",
    "* Using each sentence as my “documents”, create a search engine to find specific pieces of text.\n",
    "* Search for several items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d393abb-800e-4309-9abe-f36cd3867ec3",
   "metadata": {
    "id": "1d393abb-800e-4309-9abe-f36cd3867ec3",
    "outputId": "ca3697a8-8c90-4fa7-a2b1-5599f03e8b95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = DF_new['processed'].to_list()\n",
    "#sentences = DF['processed'].to_list()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cbfb136-4566-4453-a1c5-ccc39f042e86",
   "metadata": {
    "id": "3cbfb136-4566-4453-a1c5-ccc39f042e86"
   },
   "outputs": [],
   "source": [
    "## breaking the data into 3 smaller batches and processing each batch separately to manage memory usage better.\n",
    "index = len(sentences)//3\n",
    "\n",
    "sentences_1 = sentences[0:index]\n",
    "sentences_2 = sentences[index:(index+index)]\n",
    "sentences_3 = sentences[(index+index):((index+index+index)+2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "596c1d73-e770-47b8-8960-640739f0fa60",
   "metadata": {
    "id": "596c1d73-e770-47b8-8960-640739f0fa60",
    "outputId": "adc3f296-7cb3-40a4-85a9-c64e286dbf02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('msmarco-MiniLM-L-12-v3')\n",
    "embeddings_1 = model.encode(sentences_1)\n",
    "embeddings_2 = model.encode(sentences_2)\n",
    "embeddings_3 = model.encode(sentences_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baed9f11-3652-4b4a-ab8a-aad9ad96431c",
   "metadata": {
    "id": "baed9f11-3652-4b4a-ab8a-aad9ad96431c",
    "outputId": "c129f5be-26f0-4b0a-92aa-3380022a3b57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Concatenate along the first axis (axis=0)\n",
    "IVC_embed = np.concatenate((embeddings_1, embeddings_2, embeddings_3), axis=0)\n",
    "len(IVC_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8430da6-4446-4070-85cf-72c1e5fe438b",
   "metadata": {
    "id": "b8430da6-4446-4070-85cf-72c1e5fe438b"
   },
   "outputs": [],
   "source": [
    "# Create an index using FAISS\n",
    "index = faiss.IndexFlatL2(IVC_embed.shape[1])\n",
    "index.add(IVC_embed)\n",
    "faiss.write_index(index, 'index_IVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c1cc026-fb9f-4c28-b8b1-28fb26e62b15",
   "metadata": {
    "id": "6c1cc026-fb9f-4c28-b8b1-28fb26e62b15",
    "outputId": "da0a74ca-af8d-4091-cdce-b1bbe5bd8435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totaltime: 0.21999406814575195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"This site provides evidence of multiple social groups occupying the same village but using different pottery and living in different types of houses : `` over time the Late Harappan pottery was gradually replaced by Painted Grey ware pottery , '' and other cultural changes indicated by archaeology include the introduction of the horse , iron tools , and new religious practices .\",\n",
       " \"The pottery of the Late Harappan period is described as `` showing some continuity with mature Harappan pottery traditions '' , but also distinctive differences .\",\n",
       " 'Eventually an agreement was reached , whereby the finds , totalling some 12,000 objects ( most sherds of pottery ) , were split equally between the countries ; in some cases this was taken very literally , with some necklaces and girdles having their beads separated into two piles .',\n",
       " 'At sites such as Bhagwanpura ( in Haryana ) , archaeological excavations have discovered an overlap between the final phase of Late Harappan pottery and the earliest phase of Painted Grey Ware pottery , the latter being associated with the Vedic culture and dating from around 1200 BCE .',\n",
       " 'Formerly typical artifacts such as stone weights and female figurines became rare .']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Search for several items.\n",
    "\n",
    "# read in the index later when you need to use this again\n",
    "index = faiss.read_index('index_IVC')\n",
    "# you do have to have the model open too\n",
    "model = SentenceTransformer('msmarco-MiniLM-L-12-v3')\n",
    "\n",
    "search(\"pottery\", model, DF_new['processed'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83519075-6c19-4c4a-9d53-d428d0b9f966",
   "metadata": {
    "id": "83519075-6c19-4c4a-9d53-d428d0b9f966",
    "outputId": "98197121-e4bf-4840-af12-8d437ad59f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totaltime: 0.01557612419128418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Aryan migration See also : Vedic period and Indo-Aryan migrations Painted pottery urns from Harappa ( Cemetery H culture , c. 1900–1300 BCE ) , National Museum , New Delhi In 1953 Sir Mortimer Wheeler proposed that the invasion of an Indo-European tribe from Central Asia , the `` Aryans '' , caused the decline of the Indus civilisation .\",\n",
       " 'The latest research shows that Indus Valley people migrated from villages to cities .',\n",
       " 'document intensive caravan trade with Central Asia and the Iranian plateau .',\n",
       " 'Continuity and coexistence Archaeological excavations indicate that the decline of Harappa drove people eastward .',\n",
       " 'The residents then migrated towards the Ganges basin in the east , where they established smaller villages and isolated farms .']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"migration\", model, DF_new['processed'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8708987e-8948-4585-882e-d054200e79c2",
   "metadata": {
    "id": "8708987e-8948-4585-882e-d054200e79c2",
    "outputId": "79df0d71-380c-449a-8ac5-759b4dc15661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totaltime: 0.014929056167602539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Finnish Indologist Asko Parpola concludes that the uniformity of the Indus inscriptions precludes any possibility of widely different languages being used , and that an early form of Dravidian language must have been the language of the Indus people .',\n",
       " \"published in Science , computer scientists , comparing the pattern of symbols to various linguistic scripts and non-linguistic systems , including DNA and a computer programming language , found that the Indus script 's pattern is closer to that of spoken words , supporting the hypothesis that it codes for an as-yet-unknown language .\",\n",
       " 'have also demonstrated that a comparison of a non-linguistic system like medieval heraldic signs with natural languages yields results similar to those that Rao et al .',\n",
       " 'Today , the Dravidian language family is concentrated mostly in southern India and northern and eastern Sri Lanka , but pockets of it still remain throughout the rest of India and Pakistan ( the Brahui language ) , which lends credence to the theory .',\n",
       " 'Language See also : Substratum in Vedic Sanskrit , Harappan language , and Origins of Dravidian peoples It has often been suggested that the bearers of the IVC corresponded to proto-Dravidians linguistically , the break-up of proto-Dravidian corresponding to the break-up of the Late Harappan culture .']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"language\", model, DF_new['processed'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791557e-749d-4c2b-abe5-8c20aec81813",
   "metadata": {
    "id": "4791557e-749d-4c2b-abe5-8c20aec81813"
   },
   "source": [
    "#### Search Engine Summary\n",
    "\n",
    "**&nbsp;1. Examine the results and comment on how well I think the search engine worked.**<br>\n",
    "From the results, it's evident that the search engine operates with precision. It adeptly retrieved sentences that contained specific keywords such as `pottery`, `migration`, and `language`. The search engine consistently produced relevant results for each query, including the term and its contextual usage within the text.\n",
    "\n",
    "1. **\"pottery\" Query:** The results are comprehensive, including references to multiple social groups using different pottery, cultural changes in house types, and changes in pottery over time. The text even delves into how Harappan pottery traditions show continuity and distinctions with later periods, showcasing the search engine's depth of findings.\n",
    "2. **\"migration\" Query**: The results discuss the migration of people from rural areas to cities, which aligns with historical migrations. It includes references to archaeological findings that support this migration, tying in the Indo-European migrations and their implications.\n",
    "3. **\"language\" Query**: The results delve into the uniformity of Indus inscriptions, arguing against the presence of widely different languages among the Indus people and discussing linguistic symbols and non-linguistic systems. The response is relevant to the query, providing insights into linguistic analyses and theories concerning the Indus Valley Civilization, which is pertinent to a query on \"language.\"\n",
    "\n",
    "Overall, the search engine works well, with fast response times and accurate text retrieval based on the input queries, demonstrating relevance and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10a1c5-506b-45db-b03f-db0e747113df",
   "metadata": {
    "id": "bb10a1c5-506b-45db-b03f-db0e747113df"
   },
   "source": [
    "### Recommendation System\n",
    "\n",
    "* Using the same “documents”, create a recommendation system based on the sentences.\n",
    "* Search for similar words within the recommendation system (i.e., search for themes in your document like “love”/”war”, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d534bab-e26f-48a6-93ba-201d1b9d1064",
   "metadata": {
    "id": "9d534bab-e26f-48a6-93ba-201d1b9d1064",
    "outputId": "a9cdf0a9-57a1-461b-d21d-fb35405dcac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for doc2vec, build and save a doc2vec model.\n",
    "#sentences = DF_new['clean'].to_list()\n",
    "d2vtrain = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(sentences)]\n",
    "\n",
    "# Build and Train Doc2Vec Model\n",
    "model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm=1, epochs=100)\n",
    "model.build_vocab(d2vtrain)\n",
    "\n",
    "# Train the model\n",
    "model.train(d2vtrain, total_examples = model.corpus_count, epochs = model.epochs)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"d2v_ivc.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebd8bce8-4637-468a-8ab0-caf2b9a8c1ed",
   "metadata": {
    "id": "ebd8bce8-4637-468a-8ab0-caf2b9a8c1ed",
    "outputId": "58d97e23-4ce2-4cf7-866d-6edfa46b3197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('24', 0.8722306489944458), ('138', 0.8180112242698669), ('136', 0.8083223104476929), ('114', 0.8082464933395386), ('126', 0.8025462031364441), ('22', 0.7984138131141663), ('78', 0.7850322723388672), ('124', 0.7814505100250244), ('8', 0.7801505923271179), ('351', 0.7730388641357422)]\n",
      "\n",
      "############################## Recommended Sentences ##############################\n",
      "1). In the following millennia , settled life made inroads into the Indus plains , setting the stage for the growth of rural and urban settlements . \n",
      "\n",
      "2). As seen in Harappa , Mohenjo-daro and the recently partially excavated Rakhigarhi , this urban plan included the world 's first known urban sanitation systems . \n",
      "\n",
      "3). Cities Main article : Harappan architecture A sophisticated and technologically advanced urban culture is evident in the Indus Valley Civilisation , making them the first urban centre in the region . \n",
      "\n",
      "4). Kot Diji represents the phase leading up to Mature Harappan , with the citadel representing centralised authority and an increasingly urban quality of life . \n",
      "\n",
      "5). Brooke further notes that the development of advanced cities coincides with a reduction in rainfall , which may have triggered a reorganisation into larger urban centres . \n",
      "\n",
      "6). In addition , there was a region with disparate flora , fauna , and habitats , up to ten times as large , which had been shaped culturally and economically by the Indus . \n",
      "\n",
      "7). By 2002 , over 1,000 Mature Harappan cities and settlements had been reported , of which just under a hundred had been excavated , mainly in the general region of the Indus and Ghaggar-Hakra rivers and their tributaries ; however , there are only five major urban sites : Harappa , Mohenjo-daro , Dholavira , Ganeriwala and Rakhigarhi . \n",
      "\n",
      "8). Flood-supported farming led to large agricultural surpluses , which in turn supported the development of cities . \n",
      "\n",
      "9). The cities of the ancient Indus were noted for their urban planning , baked brick houses , elaborate drainage systems , water supply systems , clusters of large non-residential buildings , and techniques of handicraft and metallurgy . \n",
      "\n",
      "10). Urban amenities such as drains and the public bath were no longer maintained , and newer buildings were `` poorly constructed '' . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = Doc2Vec.load(\"d2v_ivc.model\")\n",
    "\n",
    "# query\n",
    "query = \"urban planning\"\n",
    "query_vector = model.infer_vector(word_tokenize(query))\n",
    "similar_sentences = model.dv.most_similar([query_vector])\n",
    "\n",
    "# Print similar sentences\n",
    "print(similar_sentences)\n",
    "\n",
    "# Print recommended sentences\n",
    "print(\"\\n############################## Recommended Sentences ##############################\")\n",
    "for i in range(len(similar_sentences)):\n",
    "    print(str(i+1)+\").\", sentences[int(similar_sentences[i][0])],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c952e45b-6e11-4102-9884-c81f4be66cf4",
   "metadata": {
    "id": "c952e45b-6e11-4102-9884-c81f4be66cf4",
    "outputId": "5fa75aa7-7dbb-4893-bbc0-e5c125ad96c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('14', 0.8282967209815979), ('125', 0.8028552532196045), ('13', 0.79131019115448), ('148', 0.7436484098434448), ('284', 0.7402262091636658), ('223', 0.7376647591590881), ('181', 0.7289215922355652), ('239', 0.7142527103424072), ('151', 0.7079241871833801), ('89', 0.7072920799255371)]\n",
      "\n",
      "############################## Recommended Sentences ##############################\n",
      "1). A relationship with the Dravidian or Elamo-Dravidian language family is favoured by a section of scholars . \n",
      "\n",
      "2). The IVC residents did not develop irrigation capabilities , relying mainly on the seasonal monsoons leading to summer floods . \n",
      "\n",
      "3). The Harappan language is not directly attested , and its affiliations are uncertain , as the Indus script has remained undeciphered . \n",
      "\n",
      "4). There is no conclusive evidence of palaces or temples . \n",
      "\n",
      "5). Finnish Indologist Asko Parpola concludes that the uniformity of the Indus inscriptions precludes any possibility of widely different languages being used , and that an early form of Dravidian language must have been the language of the Indus people . \n",
      "\n",
      "6). An extensive canal network , used for irrigation , has however also been discovered by H.-P . \n",
      "\n",
      "7). As yet , there is insufficient evidence to substantiate claims that the image had religious or cultic significance , but the prevalence of the image raises the question of whether or not the animals in images of the IVC are religious symbols . \n",
      "\n",
      "8). We regard either interpretation as still unproven , but favour the latter . \n",
      "\n",
      "9). Although the citadels were walled , it is far from clear that these structures were defensive . \n",
      "\n",
      "10). Several periodisations are employed for the IVC . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = Doc2Vec.load(\"d2v_ivc.model\")\n",
    "\n",
    "# query\n",
    "query = \"language\"\n",
    "query_vector = model.infer_vector(word_tokenize(query))\n",
    "similar_sentences = model.dv.most_similar([query_vector])\n",
    "\n",
    "# Print similar sentences\n",
    "print(similar_sentences)\n",
    "\n",
    "# Print recommended sentences\n",
    "print(\"\\n############################## Recommended Sentences ##############################\")\n",
    "for i in range(len(similar_sentences)):\n",
    "    print(str(i+1)+\").\", sentences[int(similar_sentences[i][0])],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee18edc-796b-4882-b035-de70653758a5",
   "metadata": {
    "id": "8ee18edc-796b-4882-b035-de70653758a5"
   },
   "source": [
    "#### Recommendation System Summary\n",
    "\n",
    "**&nbsp;1. Does the recommendation system show similar sentences to the topic I mentioned? What I think might be a better set of text for recommendations?**<br>\n",
    "The recommendation system effectively retrieved sentences related to specific queries like _\"urban planning\"_ and _\"language\"_, demonstrating its capability to fetch contextually relevant information from the `Indus Valley Civilization (IVC)` document. For _\"urban planning\"_, the system returned sentences on developing urban centers and sanitation systems, showcasing its semantic understanding of urban infrastructure. Similarly, for _\"language\"_, it accurately retrieved discussions on potential language families and the nature of the Indus script, indicating its proficiency in handling specific and abstract concepts.\n",
    "\n",
    "However, the dataset could be expanded to enhance the system's utility and accuracy. Incorporating a broader range of documents covering various aspects of the IVC, including interdisciplinary studies and recent archaeological findings, would provide richer content and accuracy for recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba3f01-1310-4f17-bd30-36ba0aca30fe",
   "metadata": {
    "id": "83ba3f01-1310-4f17-bd30-36ba0aca30fe"
   },
   "source": [
    "### Text Summaries\n",
    "\n",
    "* Create a human summary of the text.\n",
    "* Create text summaries using LSA, TextRank, and Topic Modeling.\n",
    "* Assess those summaries using the Rouge-N analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80094dc9-d051-4f40-a342-269e2678e4cc",
   "metadata": {
    "id": "80094dc9-d051-4f40-a342-269e2678e4cc"
   },
   "outputs": [],
   "source": [
    "human_summary = \"The Indus Valley Civilization, also known as the Harappan Civilization, was a Bronze Age civilization in South Asia \\\n",
    "that lasted from approximately 3300 BCE to 1300 BCE. It was one of the three early civilizations of the Near East and South Asia, \\\n",
    "and it was the most widespread, covering much of present-day Pakistan and northwestern India. \\\n",
    "The civilization is noted for its advanced urban planning, including using baked brick in construction, \\\n",
    "elaborate drainage systems and water supply systems. It also had large, non-residential buildings and was known for its handicrafts and \\\n",
    "metallurgy skills. Major urban centers like Mohenjo-Daro and Harappa likely had populations \\\n",
    "between 30,000 and 60,000 people at their peak, and the overall population may have been between one and five million. \\\n",
    "The decline of the civilization is believed to have been caused by a drying of the region, which reduced the water supply and \\\n",
    "led to its eventual demise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88d4b3d2-f286-47f2-95d1-8e5b36b292a3",
   "metadata": {
    "id": "88d4b3d2-f286-47f2-95d1-8e5b36b292a3",
    "outputId": "290cf68f-67ea-4b17-d1ce-f5a11a0686d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation[1] (IVC), also k...</td>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>The Indus Valley Civilisation IVC also known I...</td>\n",
       "      <td>the indus valley civilisation ivc also known i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2][a] Together with ancient Egypt and Mesopot...</td>\n",
       "      <td>Together with ancient Egypt and Mesopotamia, ...</td>\n",
       "      <td>Together ancient Egypt Mesopotamia one three e...</td>\n",
       "      <td>together ancient egypt mesopotamia one three e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3][b] The civilisation flourished both in the...</td>\n",
       "      <td>The civilisation flourished both in the alluv...</td>\n",
       "      <td>The civilisation flourished alluvial plain Ind...</td>\n",
       "      <td>the civilisation flourished alluvial plain ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2][4]\\nThe term Harappan is sometimes applied...</td>\n",
       "      <td>The term Harappan is sometimes applied to the...</td>\n",
       "      <td>The term Harappan sometimes applied Indus civi...</td>\n",
       "      <td>the term harappan sometimes applied indus civi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5][c] The discovery of Harappa and soon after...</td>\n",
       "      <td>The discovery of Harappa and soon afterwards ...</td>\n",
       "      <td>The discovery Harappa soon afterwards culminat...</td>\n",
       "      <td>the discovery harappa soon afterwards culminat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Indus Valley Civilisation[1] (IVC), also k...   \n",
       "1  [2][a] Together with ancient Egypt and Mesopot...   \n",
       "2  [3][b] The civilisation flourished both in the...   \n",
       "3  [2][4]\\nThe term Harappan is sometimes applied...   \n",
       "4  [5][c] The discovery of Harappa and soon after...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1   Together with ancient Egypt and Mesopotamia, ...   \n",
       "2   The civilisation flourished both in the alluv...   \n",
       "3   The term Harappan is sometimes applied to the...   \n",
       "4   The discovery of Harappa and soon afterwards ...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  The Indus Valley Civilisation IVC also known I...   \n",
       "1  Together ancient Egypt Mesopotamia one three e...   \n",
       "2  The civilisation flourished alluvial plain Ind...   \n",
       "3  The term Harappan sometimes applied Indus civi...   \n",
       "4  The discovery Harappa soon afterwards culminat...   \n",
       "\n",
       "                                          normalized  \n",
       "0  the indus valley civilisation ivc also known i...  \n",
       "1  together ancient egypt mesopotamia one three e...  \n",
       "2  the civilisation flourished alluvial plain ind...  \n",
       "3  the term harappan sometimes applied indus civi...  \n",
       "4  the discovery harappa soon afterwards culminat...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb1ab7-04ff-4f5b-8537-893c632292c3",
   "metadata": {
    "id": "2eeb1ab7-04ff-4f5b-8537-893c632292c3"
   },
   "source": [
    "#### Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a59018b4-b6c3-4547-b8d4-71beb3896265",
   "metadata": {
    "id": "a59018b4-b6c3-4547-b8d4-71beb3896265",
    "outputId": "d9048dd8-4a6f-4f32-dd80-66e80ad653e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\", \"Although over a thousand Mature Harappan sites have been reported and nearly a hundred excavated , there are five major urban centres : Mohenjo-daro in the lower Indus Valley ( declared a UNESCO World Heritage Site in 1980 as `` Archaeological Ruins at Moenjodaro \\'\\' ) , Harappa in the western Punjab region , Ganeriwala in the Cholistan Desert , Dholavira in western Gujarat ( declared a UNESCO World Heritage Site in 2021 as `` Dholavira : A Harappan City \\'\\' ) , and Rakhigarhi in Haryana . \\', \\'According to archaeologist Ratnagar , many Ghaggar-Hakra sites in India and Indus Valley sites in Pakistan are actually those of local cultures ; some sites display contact with Harappan civilisation , but only a few are fully developed Harappan ones . \\', \"Chronology Main article : Periodisation of the Indus Valley Civilisation History of South Asia Outline Palaeolithic ( 2,500,000–250,000 BC ) Madrasian culture Soanian culture Neolithic ( 10,800–3300 BC ) Bhirrana culture ( 7570–6200 BC ) Mehr'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentences = DF['processed'].to_list()\n",
    "num_summary_sentences = 5\n",
    "# be sure to put in one big long string\n",
    "# this will parse things into sentences for summarization\n",
    "parser = PlaintextParser.from_string(sentences, Tokenizer(LANGUAGE))\n",
    "# builds a summarizer with a stemmer (which grabs english from above)\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "# add the stops for the language we set (english)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "tr_sum = []\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentences):\n",
    "    tr_sum.append(str(sentence))\n",
    "\n",
    "tr_sum = \" \".join(tr_sum)\n",
    "\n",
    "tr_sum[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176c0de-b32c-4abf-9366-4797abaaca29",
   "metadata": {
    "id": "d176c0de-b32c-4abf-9366-4797abaaca29"
   },
   "source": [
    "#### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6c6f244-3323-4319-9bd6-7e6cb740694c",
   "metadata": {
    "id": "d6c6f244-3323-4319-9bd6-7e6cb740694c",
    "outputId": "5be0aed6-58ac-4ed8-acf1-053d22f2a527"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"', 'By 1924 , Marshall had become convinced of the significance of the finds , and on 24 September 1924 , made a tentative but conspicuous public intimation in the Illustrated London News : `` Not often has it been given to archaeologists , as it was given to Schliemann at Tiryns and Mycenae , or to Stein in the deserts of Turkestan , to light upon the remains of a long forgotten civilisation . ', 'Judging from the dispersal of Indus civilisation artefacts , the trade networks economically integrated a huge area , including portions of Afghanistan , the coastal regions of Persia connected by the Gulf of Oman from the Arabian Sea , northern and western India , and Mesopotamia , leading to the development of Indus-Mesopotamia relations . ', '( 2016 ) confirms that Indus populations were the earliest people to use complex multi-cropping strategies across both seasons , growing foods during summer ( rice , millets and beans ) and winter ( wheat , barley and pulses ) , which required differ\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = LsaSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "lsa_sum = []\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentences):\n",
    "    lsa_sum.append(str(sentence))\n",
    "\n",
    "lsa_sum = \" \".join(lsa_sum)\n",
    "\n",
    "lsa_sum[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd484be9-08ab-44be-b488-7e61eef7dfb9",
   "metadata": {
    "id": "bd484be9-08ab-44be-b488-7e61eef7dfb9"
   },
   "source": [
    "#### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "966d8a02-f51e-4645-a18d-d6acd340da9e",
   "metadata": {
    "id": "966d8a02-f51e-4645-a18d-d6acd340da9e",
    "outputId": "0ea0b127-2de6-463b-d914-04e6e03492f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Following a tradition in archaeology , the civilisation is sometimes referred to as the Harappan , after its type site , Harappa , the first site to be excavated in the 1920s ; this is notably true of usage employed by the Archaeological Survey of India after India 's independence in 1947 . It is claimed by its excavator to have been a dockyard , connected by channels to a neighbouring estuary . They were among the first to develop a system of uniform weights and measures . Authority and governance Archaeological records provide no immediate answers for a centre of power or for depictions of people in power in Harappan society . There was no single ruler but several cities like Mohenjo-daro had a separate ruler , Harappa another , and so forth .\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember all the stuff from earlier that was loaded\n",
    "# Create a dictionary representation of the documents.\n",
    "# use our list of sentences from earlier\n",
    "processed_sentences = [preprocess(sent) for sent in sentences]\n",
    "# create the vocabulary list\n",
    "dictionary = Dictionary(processed_sentences)\n",
    "# convert to a term by document matrix\n",
    "corpus = [dictionary.doc2bow(sent) for sent in processed_sentences]\n",
    "\n",
    "# Train the topic model\n",
    "LDAmodel = LdaModel(corpus = corpus,\n",
    "                id2word = dictionary,\n",
    "                iterations = 400,\n",
    "                num_topics = 10,\n",
    "                random_state = 100,\n",
    "                update_every = 1,\n",
    "                chunksize = 100,\n",
    "                passes = 10,\n",
    "                alpha = 'auto',\n",
    "                per_word_topics = True)\n",
    "\n",
    "probs = [LDAmodel.get_document_topics(sentence) for sentence in corpus]\n",
    "\n",
    "save_probs = []\n",
    "i = 0 # looping variable\n",
    "for document in probs:\n",
    "  for (topic, prob) in document:\n",
    "    if topic == 0: # this is the topic zero but you can pick another one\n",
    "      save_probs.append((sentences[i], prob))\n",
    "  i = i + 1\n",
    "\n",
    "DF_lda = pd.DataFrame(save_probs, columns = [\"sentence\", \"prob\"])\n",
    "\n",
    "topic_sum = \" \".join(DF_lda.sort_values(by = [\"prob\"], ascending = False)[0:num_summary_sentences].sentence)\n",
    "topic_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc44cbe7-5a5c-453e-82cf-3c8c7c4228f2",
   "metadata": {
    "id": "fc44cbe7-5a5c-453e-82cf-3c8c7c4228f2",
    "outputId": "a419e137-15dd-45ea-9915-a823f4fc1aad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.022*\"religious\" + 0.017*\"symbols\" + 0.016*\"decline\" + 0.011*\"pashupati\" + 0.011*\"indian\" + 0.010*\"however\" + 0.010*\"like\" + 0.010*\"several\" + 0.008*\"linguistic\" + 0.008*\"languages\"'),\n",
       " (1,\n",
       "  '0.045*\"indus\" + 0.028*\"valley\" + 0.021*\"river\" + 0.020*\"civilisation\" + 0.016*\"inscriptions\" + 0.014*\"identified\" + 0.011*\"religion\" + 0.010*\"cattle\" + 0.009*\"length\" + 0.008*\"pakistan\"'),\n",
       " (2,\n",
       "  '0.039*\"used\" + 0.015*\"language\" + 0.014*\"even\" + 0.012*\"basin\" + 0.012*\"indus\" + 0.009*\"largely\" + 0.008*\"support\" + 0.008*\"hypothesis\" + 0.008*\"also\" + 0.007*\"individuals\"')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top topics\n",
    "top_topics = LDAmodel.print_topics(num_words=10)\n",
    "top_topics[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc89ac-ad33-467b-a11e-01b5933d17b2",
   "metadata": {
    "id": "21cc89ac-ad33-467b-a11e-01b5933d17b2"
   },
   "source": [
    "#### Rouge-N analyzer\n",
    "* Assess those summaries using the Rouge-N analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2997c58f-35db-4a85-987d-d318fccdaaf7",
   "metadata": {
    "id": "2997c58f-35db-4a85-987d-d318fccdaaf7",
    "outputId": "17d01851-8976-4468-8e65-247086ace227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################## Compared to human-generated summary ##############################\n",
      "#### TextRank ####\n",
      "rouge1 Precision: 0.07 Recall: 0.45 fmeasure: 0.12\n",
      "\n",
      "#### LSA ####\n",
      "rouge1 Precision: 0.24 Recall: 0.40 fmeasure: 0.30\n",
      "\n",
      "#### Topic Modeling ####\n",
      "rouge1 Precision: 0.34 Recall: 0.27 fmeasure: 0.30\n"
     ]
    }
   ],
   "source": [
    "# build a blank model\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "# add the gold standard and summary you want to compare\n",
    "# scores = scorer.score(gold_standard, summary)\n",
    "# print the scores\n",
    "# print_rouge_score(scores)\n",
    "\n",
    "# compare to human-generated summary\n",
    "print(\"\\n############################## Compared to human-generated summary ##############################\")\n",
    "print(\"#### TextRank ####\")\n",
    "print_rouge_score(scorer.score(human_summary, tr_sum))\n",
    "\n",
    "print(\"\\n#### LSA ####\")\n",
    "print_rouge_score(scorer.score(human_summary, lsa_sum))\n",
    "\n",
    "print(\"\\n#### Topic Modeling ####\")\n",
    "print_rouge_score(scorer.score(human_summary, topic_sum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81241e7a-671b-4c19-95f5-ed9d37269982",
   "metadata": {
    "id": "81241e7a-671b-4c19-95f5-ed9d37269982"
   },
   "source": [
    "### Text Summarization Summary\n",
    "\n",
    "**&nbsp;1. Summarizing the results from the text summarization section. Do I feel the bag of words methods are useful for text summarization? Can I make a good summary by grabbing sentences from the text, or should I explore text generation more? Do I think enterprise search engines are useful for my work? What other things might I do with the information from text summarization?**\n",
    "\n",
    "The text summarization section focused on extracting key points from the Wikipedia article on the Indus Valley Civilization using various methods, including the bag of words approach and sentence extraction based on relevance and keyword density. These techniques effectively distilled the article into its most essential elements, highlighting major topics such as the geographical spread, cultural practices, and notable archaeological findings of the IVC. While the bag of words method provided a straightforward, keyword-based overview, it sometimes needed to include the nuanced connections between concepts vital for a holistic understanding of the subject matter. This indicates that while bag of words methods can identify prominent themes or keywords, they may only sometimes construct a coherent narrative or capture the deeper storyline within the text.\n",
    "\n",
    "Based on the `Rouge-N scores` provided, the best summary compared to the human-generated summary was the one generated by __Topic Modeling__. It had the highest **fmeasure** of **0.30** compared to the _TextRank(0.12)_ and _LSA(0.30)_ summaries. This suggests that the Topic Modeling summarizer was more effective in capturing the essential points and reflecting the content and style of the human summary.\n",
    "\n",
    "Considering the limitations of basic summarization methods like bag of words, exploring more advanced text generation techniques, such as those employing machine learning models like BERT or GPT, might yield better results. Through their understanding of language models and contextual relationships, these models can generate summaries that maintain narrative flow and offer a more nuanced understanding of complex texts. Additionally, enterprise search engines that utilize these sophisticated summarization techniques could be highly beneficial for quickly retrieving and condensing vast amounts of information. This would be particularly useful in professional fields where large volumes of data are common, such as academic research, legal studies, or historical documentation. Further applications of text summarization could include:\n",
    "* Creating executive summaries for lengthy reports.\n",
    "* Generating concise explanations for educational materials.\n",
    "* Even developing automated content for informational websites, each of which would benefit from more advanced, context-aware summarization capabilities that go beyond simple keyword extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af5dc55-cc90-4c6d-8567-43d0d633d545",
   "metadata": {
    "id": "1af5dc55-cc90-4c6d-8567-43d0d633d545"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c410bc5-c1b3-4a2c-9e88-d3d44115909a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "7c410bc5-c1b3-4a2c-9e88-d3d44115909a",
    "outputId": "37fd0062-ec1a-43e2-9ef1-4c492ae78c14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>processed</th>\n",
       "      <th>normalized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation[1] (IVC), also k...</td>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>The Indus Valley Civilisation IVC also known I...</td>\n",
       "      <td>the indus valley civilisation ivc also known i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2][a] Together with ancient Egypt and Mesopot...</td>\n",
       "      <td>Together with ancient Egypt and Mesopotamia, ...</td>\n",
       "      <td>Together ancient Egypt Mesopotamia one three e...</td>\n",
       "      <td>together ancient egypt mesopotamia one three e...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3][b] The civilisation flourished both in the...</td>\n",
       "      <td>The civilisation flourished both in the alluv...</td>\n",
       "      <td>The civilisation flourished alluvial plain Ind...</td>\n",
       "      <td>the civilisation flourished alluvial plain ind...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2][4]\\nThe term Harappan is sometimes applied...</td>\n",
       "      <td>The term Harappan is sometimes applied to the...</td>\n",
       "      <td>The term Harappan sometimes applied Indus civi...</td>\n",
       "      <td>the term harappan sometimes applied indus civi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5][c] The discovery of Harappa and soon after...</td>\n",
       "      <td>The discovery of Harappa and soon afterwards ...</td>\n",
       "      <td>The discovery Harappa soon afterwards culminat...</td>\n",
       "      <td>the discovery harappa soon afterwards culminat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Indus Valley Civilisation[1] (IVC), also k...   \n",
       "1  [2][a] Together with ancient Egypt and Mesopot...   \n",
       "2  [3][b] The civilisation flourished both in the...   \n",
       "3  [2][4]\\nThe term Harappan is sometimes applied...   \n",
       "4  [5][c] The discovery of Harappa and soon after...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...   \n",
       "1   Together with ancient Egypt and Mesopotamia, ...   \n",
       "2   The civilisation flourished both in the alluv...   \n",
       "3   The term Harappan is sometimes applied to the...   \n",
       "4   The discovery of Harappa and soon afterwards ...   \n",
       "\n",
       "                                           processed  \\\n",
       "0  The Indus Valley Civilisation IVC also known I...   \n",
       "1  Together ancient Egypt Mesopotamia one three e...   \n",
       "2  The civilisation flourished alluvial plain Ind...   \n",
       "3  The term Harappan sometimes applied Indus civi...   \n",
       "4  The discovery Harappa soon afterwards culminat...   \n",
       "\n",
       "                                          normalized sentiment  \n",
       "0  the indus valley civilisation ivc also known i...  positive  \n",
       "1  together ancient egypt mesopotamia one three e...  positive  \n",
       "2  the civilisation flourished alluvial plain ind...  negative  \n",
       "3  the term harappan sometimes applied indus civi...  positive  \n",
       "4  the discovery harappa soon afterwards culminat...   neutral  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Sentiment Analysis\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    # Categorize sentiment into positive, negative, and neutral\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "DF['sentiment'] = DF['normalized'].apply(analyze_sentiment)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba2f7950-5170-404e-95f5-ddc629676b2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "ba2f7950-5170-404e-95f5-ddc629676b2b",
    "outputId": "8bd07e38-2a1c-41fb-d9d9-471e9ba3e9fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Together with ancient Egypt and Mesopotamia, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The civilisation flourished both in the alluv...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The term Harappan is sometimes applied to the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The discovery of Harappa and soon afterwards ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  The Indus Valley Civilisation (IVC), also know...  positive\n",
       "1   Together with ancient Egypt and Mesopotamia, ...  positive\n",
       "2   The civilisation flourished both in the alluv...  negative\n",
       "3   The term Harappan is sometimes applied to the...  positive\n",
       "4   The discovery of Harappa and soon afterwards ...   neutral"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_classify = DF[[\"clean\",\"sentiment\"]]\n",
    "DF_classify = DF_classify.rename(columns={\"clean\":\"text\"})\n",
    "DF_classify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9a7ec41-b5fa-4127-a463-4de883902cec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9a7ec41-b5fa-4127-a463-4de883902cec",
    "outputId": "07d77164-455c-4ac3-a014-e74c44830df9"
   },
   "outputs": [],
   "source": [
    "# Preprocessing 1\n",
    "def data_clean(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.lower() # lower case\n",
    "    # punctuation ?\n",
    "    # contractions\n",
    "    text = contractions.fix(text)\n",
    "    # stop words\n",
    "    text = \" \".join([word for word in nltk.word_tokenize(text) if word not in stop_words])\n",
    "    # lemmatization\n",
    "    temp = nlp(text)\n",
    "    text = \" \".join([word.lemma_ for word in temp])\n",
    "    return(text)\n",
    "\n",
    "# Preprocessing 2\n",
    "def data_clean2(text):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub('</?[a-z]>', ' ', text)\n",
    "    text = re.sub('♪', ' ', text)\n",
    "    text = re.sub(r'\\[\\w+\\]', '', text)\n",
    "\n",
    "    # Convert emoticons to words\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    # Remove URLs and mentions\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+|@\\S+\", '', text, flags=re.MULTILINE)\n",
    "\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [word for word in text if word.isalnum()]  # Remove punctuation\n",
    "    text = [word for word in text if word not in stop_words]  # Remove stopwords\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]  # Lemmatize\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41ef54ec-c775-4b6b-8eb0-c89682413fb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "41ef54ec-c775-4b6b-8eb0-c89682413fb5",
    "outputId": "025f69d7-9da9-4a4b-8b67-e121fb6fd01b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Indus Valley Civilisation (IVC), also know...</td>\n",
       "      <td>positive</td>\n",
       "      <td>indus valley civilisation ( ivc ) , also know ...</td>\n",
       "      <td>indus valley civilisation ivc also known indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Together with ancient Egypt and Mesopotamia, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>together ancient egypt mesopotamia , one three...</td>\n",
       "      <td>together ancient egypt mesopotamia one three e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The civilisation flourished both in the alluv...</td>\n",
       "      <td>negative</td>\n",
       "      <td>civilisation flourish alluvial plain indus riv...</td>\n",
       "      <td>civilisation flourished alluvial plain indus r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The term Harappan is sometimes applied to the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>term harappan sometimes apply indus civilisati...</td>\n",
       "      <td>term harappan sometimes applied indus civilisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The discovery of Harappa and soon afterwards ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>discovery harappa soon afterwards mohenjo - da...</td>\n",
       "      <td>discovery harappa soon afterwards culmination ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0  The Indus Valley Civilisation (IVC), also know...  positive   \n",
       "1   Together with ancient Egypt and Mesopotamia, ...  positive   \n",
       "2   The civilisation flourished both in the alluv...  negative   \n",
       "3   The term Harappan is sometimes applied to the...  positive   \n",
       "4   The discovery of Harappa and soon afterwards ...   neutral   \n",
       "\n",
       "                                               clean  \\\n",
       "0  indus valley civilisation ( ivc ) , also know ...   \n",
       "1  together ancient egypt mesopotamia , one three...   \n",
       "2  civilisation flourish alluvial plain indus riv...   \n",
       "3  term harappan sometimes apply indus civilisati...   \n",
       "4  discovery harappa soon afterwards mohenjo - da...   \n",
       "\n",
       "                                              clean2  \n",
       "0  indus valley civilisation ivc also known indus...  \n",
       "1  together ancient egypt mesopotamia one three e...  \n",
       "2  civilisation flourished alluvial plain indus r...  \n",
       "3  term harappan sometimes applied indus civilisa...  \n",
       "4  discovery harappa soon afterwards culmination ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_classify['clean'] = DF_classify['text'].apply(data_clean)\n",
    "DF_classify['clean2'] = DF_classify['text'].apply(data_clean2)\n",
    "DF_classify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600da32-0240-4edb-b314-b96260386ec2",
   "metadata": {
    "id": "f600da32-0240-4edb-b314-b96260386ec2"
   },
   "source": [
    "### Split the Modeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27ce163a-94b0-4c08-9f86-85233cc6fc66",
   "metadata": {
    "id": "27ce163a-94b0-4c08-9f86-85233cc6fc66"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, # X values\n",
    "                                                        y, # Y values\n",
    "                                                        test_size = 0.2, # test size\n",
    "                                                        random_state = 89543, # random shuffle\n",
    "                                                        stratify = y)\n",
    "\n",
    "\n",
    "    print(\"################### X_train #########################\")\n",
    "    print(X_train.head())\n",
    "\n",
    "    print(\"\\n################### Y_train #########################\")\n",
    "    print(Y_train.head())\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee4a4b-6784-4049-8742-66445cfc071e",
   "metadata": {
    "id": "00ee4a4b-6784-4049-8742-66445cfc071e"
   },
   "source": [
    "### Feature Extractions\n",
    "\n",
    "* The bag of words encoding using the count vectorizer.\n",
    "* The TF-IDF normalization using the tfidf vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901d4d7-ee84-403e-890a-0d32091cd526",
   "metadata": {
    "id": "3901d4d7-ee84-403e-890a-0d32091cd526"
   },
   "source": [
    "#### Bag of words Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a92b9d5f-a690-4857-9a0c-9307ae353d22",
   "metadata": {
    "id": "a92b9d5f-a690-4857-9a0c-9307ae353d22"
   },
   "outputs": [],
   "source": [
    "def b_o_w(X_train, X_test):\n",
    "\n",
    "    # create a blank extractor\n",
    "    bow = CountVectorizer()\n",
    "\n",
    "    # fit the data to it\n",
    "    bow_train = bow.fit_transform(X_train)\n",
    "\n",
    "    # transform the second data to it matches to the fit_transform vocab\n",
    "    bow_test = bow.transform(X_test)\n",
    "\n",
    "    return bow_train, bow_test, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4645af03-93ec-4196-94c6-9c34bbb43433",
   "metadata": {
    "id": "4645af03-93ec-4196-94c6-9c34bbb43433",
    "outputId": "5a30d589-839c-4366-9bd7-bb82d12e3f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### X_train #########################\n",
      "336    late harappan late harappan period , c. 1900–1...\n",
      "34     indus valley site find often river , also anci...\n",
      "215    seal ; 3000–1500 ; baked steatite ; 2 × 2 cm ;...\n",
      "79     2008 , 616 site report india , whereas 406 sit...\n",
      "95     mehrgarh one early site evidence farming herd ...\n",
      "Name: clean, dtype: object\n",
      "\n",
      "################### Y_train #########################\n",
      "336    negative\n",
      "34      neutral\n",
      "215    positive\n",
      "79      neutral\n",
      "95      neutral\n",
      "Name: sentiment, dtype: object\n",
      "(316, 2209)\n",
      "(80, 2209)\n"
     ]
    }
   ],
   "source": [
    "# Using clean-up 1\n",
    "X_train, X_test, Y_train, Y_test = split_data(DF_classify['clean'], DF_classify['sentiment'])\n",
    "\n",
    "bow_train, bow_test, bow = b_o_w(X_train, X_test)\n",
    "print(bow_train.shape)\n",
    "print(bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bf8def8-da37-4aea-9ce2-4e1daf37cc78",
   "metadata": {
    "id": "8bf8def8-da37-4aea-9ce2-4e1daf37cc78",
    "outputId": "fe953e42-3529-436d-baca-00e705a6b3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### X_train #########################\n",
      "336    late harappan late harappan period bce bronze ...\n",
      "34     indus valley site found often river also ancie...\n",
      "215    seal bc baked steatite 2 2 cm metropolitan mus...\n",
      "79     2008 616 site reported india whereas 406 site ...\n",
      "95     mehrgarh one earliest site evidence farming he...\n",
      "Name: clean2, dtype: object\n",
      "\n",
      "################### Y_train #########################\n",
      "336    negative\n",
      "34      neutral\n",
      "215    positive\n",
      "79      neutral\n",
      "95      neutral\n",
      "Name: sentiment, dtype: object\n",
      "(316, 2089)\n",
      "(80, 2089)\n"
     ]
    }
   ],
   "source": [
    "# Using clean-up 2\n",
    "X_train, X_test, Y_train, Y_test = split_data(DF_classify['clean2'], DF_classify['sentiment'])\n",
    "\n",
    "bow_train2, bow_test2, bow2 = b_o_w(X_train, X_test)\n",
    "print(bow_train2.shape)\n",
    "print(bow_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dded8a3-6343-49ce-bbe9-c9068ef55711",
   "metadata": {
    "id": "0dded8a3-6343-49ce-bbe9-c9068ef55711"
   },
   "source": [
    "#### TF-IDF normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1662a4b-3c98-43fb-8c36-b1fe3f1e187d",
   "metadata": {
    "id": "f1662a4b-3c98-43fb-8c36-b1fe3f1e187d"
   },
   "outputs": [],
   "source": [
    "def tf_idf(X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    # create a blank extractor\n",
    "    tfidf = TfidfVectorizer()\n",
    "\n",
    "    # fit the data to it\n",
    "    tf_train = tfidf.fit_transform(X_train)\n",
    "\n",
    "    # transform the second data to it matches to the fit_transform vocab\n",
    "    tf_test = tfidf.transform(X_test)\n",
    "\n",
    "    return tf_train, tf_test, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9cee215a-a599-4180-a6ae-00682a8b779c",
   "metadata": {
    "id": "9cee215a-a599-4180-a6ae-00682a8b779c",
    "outputId": "872cb1d9-05fa-4e17-83b4-c78c81d55e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### X_train #########################\n",
      "336    late harappan late harappan period , c. 1900–1...\n",
      "34     indus valley site find often river , also anci...\n",
      "215    seal ; 3000–1500 ; baked steatite ; 2 × 2 cm ;...\n",
      "79     2008 , 616 site report india , whereas 406 sit...\n",
      "95     mehrgarh one early site evidence farming herd ...\n",
      "Name: clean, dtype: object\n",
      "\n",
      "################### Y_train #########################\n",
      "336    negative\n",
      "34      neutral\n",
      "215    positive\n",
      "79      neutral\n",
      "95      neutral\n",
      "Name: sentiment, dtype: object\n",
      "(316, 2209)\n",
      "(80, 2209)\n"
     ]
    }
   ],
   "source": [
    "# Using clean-up 1\n",
    "X_train, X_test, Y_train, Y_test = split_data(DF_classify['clean'], DF_classify['sentiment'])\n",
    "tf_train, tf_test, tfidf = tf_idf(X_train, X_test, Y_train, Y_test)\n",
    "print(tf_train.shape)\n",
    "print(tf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bae0afb1-983c-4436-a9d0-fef18b6985e7",
   "metadata": {
    "id": "bae0afb1-983c-4436-a9d0-fef18b6985e7",
    "outputId": "26d6a1d4-64b9-45db-d53a-8460633d30f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### X_train #########################\n",
      "336    late harappan late harappan period bce bronze ...\n",
      "34     indus valley site found often river also ancie...\n",
      "215    seal bc baked steatite 2 2 cm metropolitan mus...\n",
      "79     2008 616 site reported india whereas 406 site ...\n",
      "95     mehrgarh one earliest site evidence farming he...\n",
      "Name: clean2, dtype: object\n",
      "\n",
      "################### Y_train #########################\n",
      "336    negative\n",
      "34      neutral\n",
      "215    positive\n",
      "79      neutral\n",
      "95      neutral\n",
      "Name: sentiment, dtype: object\n",
      "(316, 2089)\n",
      "(80, 2089)\n"
     ]
    }
   ],
   "source": [
    "# Using clean-up 2\n",
    "X_train, X_test, Y_train, Y_test = split_data(DF_classify['clean2'], DF_classify['sentiment'])\n",
    "tf_train2, tf_test2, tfidf2 = tf_idf(X_train, X_test, Y_train, Y_test)\n",
    "print(tf_train2.shape)\n",
    "print(tf_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09208b22-7629-4037-8ae9-ca52cc6641c1",
   "metadata": {
    "id": "09208b22-7629-4037-8ae9-ca52cc6641c1"
   },
   "source": [
    "### Classify\n",
    "\n",
    "* Use at least two classification algorithms to predict the outcome of the data.\n",
    "* Include the model assessment of these predictions for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b589d8c-8c15-44d9-9b80-3e1c28d5a0f9",
   "metadata": {
    "id": "9b589d8c-8c15-44d9-9b80-3e1c28d5a0f9"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "552fab9f-66f1-4c65-8c33-7fe02dd6a7ba",
   "metadata": {
    "id": "552fab9f-66f1-4c65-8c33-7fe02dd6a7ba",
    "outputId": "1982a2ad-707b-47c8-c646-3401a5583ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22        14\n",
      "     neutral       0.53      0.80      0.64        30\n",
      "    positive       0.71      0.61      0.66        36\n",
      "\n",
      "    accuracy                           0.60        80\n",
      "   macro avg       0.58      0.52      0.51        80\n",
      "weighted avg       0.61      0.60      0.57        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# log regression\n",
    "# build a blank model\n",
    "def log_model(X_train, Y_train, X_test, Y_test):\n",
    "    logreg = LogisticRegression(max_iter = 10000)\n",
    "    # fit the training data to the model\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    # predict test cases\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    # compare predicts to the actuals\n",
    "    print(classification_report(y_true = Y_test, y_pred = y_pred))\n",
    "\n",
    "    return logreg\n",
    "\n",
    "logreg_bow = log_model(bow_train, Y_train, bow_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f7673d8-695e-456c-85de-756ea14b8ded",
   "metadata": {
    "id": "3f7673d8-695e-456c-85de-756ea14b8ded",
    "outputId": "a4e9da6f-4c94-4209-e605-638117040a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22        14\n",
      "     neutral       0.59      0.90      0.71        30\n",
      "    positive       0.77      0.64      0.70        36\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.62      0.56      0.54        80\n",
      "weighted avg       0.65      0.65      0.62        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_bow2 = log_model(bow_train2, Y_train, bow_test2, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b2c0cfb-5a1e-402a-9bac-0cb0ed848ffb",
   "metadata": {
    "id": "0b2c0cfb-5a1e-402a-9bac-0cb0ed848ffb",
    "outputId": "51759857-e2dc-4097-cfba-2a1d1268e9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        14\n",
      "     neutral       0.42      0.33      0.37        30\n",
      "    positive       0.54      0.81      0.64        36\n",
      "\n",
      "    accuracy                           0.51        80\n",
      "   macro avg       0.65      0.43      0.42        80\n",
      "weighted avg       0.57      0.51      0.47        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_tf = log_model(tf_train, Y_train, tf_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05f702eb-710d-4fc4-86b5-852ff1b14141",
   "metadata": {
    "id": "05f702eb-710d-4fc4-86b5-852ff1b14141",
    "outputId": "9c4567e8-d328-4df8-8488-4fbc6c52f563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.13        14\n",
      "     neutral       0.56      0.47      0.51        30\n",
      "    positive       0.57      0.86      0.69        36\n",
      "\n",
      "    accuracy                           0.57        80\n",
      "   macro avg       0.71      0.47      0.44        80\n",
      "weighted avg       0.64      0.57      0.52        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_tf2 = log_model(tf_train2, Y_train, tf_test2, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9c048-9fb1-4428-b3fb-ccb05a8f9198",
   "metadata": {
    "id": "bae9c048-9fb1-4428-b3fb-ccb05a8f9198"
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe74f0f7-6e28-43cb-a003-1ae314116301",
   "metadata": {
    "id": "fe74f0f7-6e28-43cb-a003-1ae314116301"
   },
   "outputs": [],
   "source": [
    "# bayes\n",
    "def naive_bayes(X_train, Y_train, X_test, Y_test):\n",
    "    # build a blank model\n",
    "    nb = MultinomialNB()\n",
    "    # fit the training data to the model\n",
    "    nb.fit(X_train, Y_train)\n",
    "    # predict test cases\n",
    "    y_pred = nb.predict(X_test)\n",
    "    # compare predicts to the actuals\n",
    "    print(classification_report(y_true = Y_test, y_pred = y_pred))\n",
    "\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba4a19f7-5b42-4fcd-b2c0-5c1c0bac1e31",
   "metadata": {
    "id": "ba4a19f7-5b42-4fcd-b2c0-5c1c0bac1e31",
    "outputId": "7ed6a609-b087-49c2-d371-c26ddfdd7263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.21      0.30        14\n",
      "     neutral       0.50      0.30      0.38        30\n",
      "    positive       0.55      0.86      0.67        36\n",
      "\n",
      "    accuracy                           0.54        80\n",
      "   macro avg       0.52      0.46      0.45        80\n",
      "weighted avg       0.52      0.54      0.50        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_bow = naive_bayes(bow_train, Y_train, bow_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd8fd3b4-7a78-46f1-a2a4-00f54a5eca68",
   "metadata": {
    "id": "dd8fd3b4-7a78-46f1-a2a4-00f54a5eca68",
    "outputId": "23b95be1-bee8-459c-b827-dc6d24081afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.21      0.33        14\n",
      "     neutral       0.52      0.37      0.43        30\n",
      "    positive       0.58      0.89      0.70        36\n",
      "\n",
      "    accuracy                           0.57        80\n",
      "   macro avg       0.62      0.49      0.49        80\n",
      "weighted avg       0.59      0.57      0.54        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_bow2 = naive_bayes(bow_train2, Y_train, bow_test2, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c4cb07c-11a6-4b84-a9bc-39df6ddab6a4",
   "metadata": {
    "id": "5c4cb07c-11a6-4b84-a9bc-39df6ddab6a4",
    "outputId": "ce6b7688-ca33-46f2-8799-556e679b373d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.33      0.13      0.19        30\n",
      "    positive       0.49      0.92      0.63        36\n",
      "\n",
      "    accuracy                           0.46        80\n",
      "   macro avg       0.27      0.35      0.28        80\n",
      "weighted avg       0.34      0.46      0.36        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "nb_tf = naive_bayes(tf_train, Y_train, tf_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "337c0236-94d8-4e30-9aba-5ba657451fd5",
   "metadata": {
    "id": "337c0236-94d8-4e30-9aba-5ba657451fd5",
    "outputId": "83cc8f1d-975d-4e3e-c78a-96acf59757df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.46      0.20      0.28        30\n",
      "    positive       0.49      0.92      0.64        36\n",
      "\n",
      "    accuracy                           0.49        80\n",
      "   macro avg       0.32      0.37      0.31        80\n",
      "weighted avg       0.39      0.49      0.39        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfd/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "nb_tf2 = naive_bayes(tf_train2, Y_train, tf_test2, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9284b-79c2-4b79-b730-abf27b8497d4",
   "metadata": {
    "id": "aac9284b-79c2-4b79-b730-abf27b8497d4"
   },
   "source": [
    "#### Lime\n",
    "**The Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "217d8c1f-6f76-483d-8260-59ab97e433f5",
   "metadata": {
    "id": "217d8c1f-6f76-483d-8260-59ab97e433f5",
    "outputId": "78f33975-38e3-4923-853e-29a6e6b9ce1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22        14\n",
      "     neutral       0.59      0.90      0.71        30\n",
      "    positive       0.77      0.64      0.70        36\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.62      0.56      0.54        80\n",
      "weighted avg       0.65      0.65      0.62        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_bow2 = log_model(bow_train2, Y_train, bow_test2, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d5fa7-0173-4c7c-8f83-060ec2989529",
   "metadata": {
    "id": "349d5fa7-0173-4c7c-8f83-060ec2989529"
   },
   "source": [
    "##### Apply to new instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06a3666c-2af7-4094-8e22-e005c740d35a",
   "metadata": {
    "id": "06a3666c-2af7-4094-8e22-e005c740d35a",
    "outputId": "deb3d1e2-9083-4367-ff44-03edcea8060e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PUT IN THE PIPELINE feature extractor, final algorithm model\n",
    "pipeline = make_pipeline(bow2, logreg_bow2)\n",
    "\n",
    "# build a blank model\n",
    "explainer = LimeTextExplainer(class_names = Y_train.sort_values().unique())\n",
    "\n",
    "id_value = 4\n",
    "\n",
    "# first argument is text\n",
    "exp = explainer.explain_instance(DF_classify.iloc[id_value]['clean2'],\n",
    "      # predict_proba only works on certain models\n",
    "      pipeline.predict_proba, num_features=10)\n",
    "\n",
    "exp.as_pyplot_figure()\n",
    "plt.show()\n",
    "\n",
    "exp.save_to_file('example.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b52b2a-610f-41e7-b054-da074ba4f8b9",
   "metadata": {
    "id": "74b52b2a-610f-41e7-b054-da074ba4f8b9"
   },
   "source": [
    "#### Interpret Using eli5\n",
    "\n",
    "* Use eli5 to determine what predicts each category label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0fa1cc69-5873-44bc-8211-e59a6c9f6039",
   "metadata": {
    "id": "0fa1cc69-5873-44bc-8211-e59a6c9f6039",
    "outputId": "eca39858-ae23-46c7-ba2a-3fadc6284111"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights-wrapper\" style=\"border-collapse: collapse; border: none; margin-bottom: 1.5em;\">\n",
       "            <tr>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=negative\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=neutral\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=positive\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                \n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.454\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        late\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.870\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        plain\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.698\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        material\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.619\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        complex\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.587\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        common\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.526\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        culture\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.502\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        included\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.464\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        alluvial\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.452\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        symbol\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.28%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 672 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.27%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1408 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.246\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.480\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 633 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.78%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1447 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.568\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        great\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.582\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        first\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.606\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        late\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.622\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        culture\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.633\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        early\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.645\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        trade\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.648\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        city\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.661\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        large\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.704\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        harappan\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.904\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        large\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.895\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        great\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.891\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        many\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.761\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        first\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.656\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        new\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.616\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mature\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.575\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ancient\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.571\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        similar\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.73%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1029 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.79%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1051 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.566\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        plain\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.848\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        late\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                \n",
       "            </tr>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(estimator = logreg_bow2, top = 10, feature_names = bow2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45f1d4-4060-4d8e-84ff-f159942e733b",
   "metadata": {
    "id": "5a45f1d4-4060-4d8e-84ff-f159942e733b"
   },
   "source": [
    "### Classification Summary\n",
    "\n",
    "**&nbsp;1. Summarizing ther results from two sections on classification. What are other things I might consider classifying from the text? What I think are the best options for feature extraction and algorithms? Do I think the systems that explain machine learning models are useful?**\n",
    "\n",
    "The classification analysis leveraged logistic regression and naive Bayes models to perform sentiment analysis on processed text data, categorizing each segment into positive, negative, or neutral sentiments. The data preprocessing involved several normalization techniques, including removing special characters, lowering case, and lemmatization, to refine the text for better performance in the machine learning model. Both logistic regression and naive Bayes were evaluated on their precision, recall, and F1-score, revealing that logistic regression generally provided superior performance, especially in distinguishing between different sentiment classes.\n",
    "\n",
    "The analysis results indicated varying levels of effectiveness in classification:\n",
    "- **Logistic Regression**: This model, with its **best performance** showing an **accuracy** of **65%** when **using** a **bag-of-words** model refined with advanced preprocessing, demonstrated a modest yet commendable accuracy. The classification report underscored the model's strength in effectively differentiating between positive and neutral sentiments, even though its performance on negative sentiments was less robust.\n",
    "- **Naive Bayes**: This model performed slightly lower in accuracy than logistic regression. However, it still demonstrated reasonable effectiveness in identifying positive sentiments, which it classified correctly with higher precision and recall compared to negative or neutral categories.\n",
    "\n",
    "From the classification effectiveness and the results, it is evident that while the basic text processing and classic machine learning models provided a foundational approach, there is room for enhancement. Incorporating more sophisticated NLP techniques, such as embedding layers from pre-trained models like BERT, could potentially improve the nuances and contextual understanding within the classifications. Additionally, the utility of model explanation systems such as LIME and ELI5 proved beneficial in interpreting the influence of various features on the model predictions, suggesting that expanding their use could help in further refining and troubleshooting the models. This approach not only ensures better model performance but also underscores the critical importance of transparency and trust in automated text analysis applications, particularly in domains requiring high accuracy and reliability such as academic research and content-sensitive industries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a83ecc-5e90-4645-96bd-2d9f0df4366e",
   "metadata": {
    "id": "30a83ecc-5e90-4645-96bd-2d9f0df4366e"
   },
   "source": [
    "## Comparing NLP summaries with Automated summarization SOTA models like ChatGPT4\n",
    "* **Question**: Do traditional NLP summarization algorithms generate summaries are comparably informative and concise as those to automated summarization tools, such as ChatGPT\n",
    "* **NLP Technique**: Create text summaries using LSA, TextRank, and Topic Modeling and compare them with the summary generated by ChatGPT4 using Rouge-N analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c6809f4-719d-46e1-83cb-bccb54a9986d",
   "metadata": {
    "id": "0c6809f4-719d-46e1-83cb-bccb54a9986d"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = 'personal_key_removed'\n",
    "\n",
    "def chatgpt_response(prompt):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Extract and return the response text\n",
    "        return response.choices[0].message['content']\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c787e582-25e5-40a1-be16-3d351de9cc49",
   "metadata": {
    "id": "c787e582-25e5-40a1-be16-3d351de9cc49"
   },
   "outputs": [],
   "source": [
    "def generate_summary_with_chatgpt():\n",
    "    prompt = f\"Generate summary about the Indus Valley Civilization (IVC)\"\n",
    "    return chatgpt_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "300e876d-48e4-4816-9ba6-742e773c844d",
   "metadata": {
    "id": "300e876d-48e4-4816-9ba6-742e773c844d",
    "outputId": "62b0fc31-9fa8-4fb8-9e67-ae1e6acf7513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indus Valley Civilization (IVC), also known as Harappan Civilization, was a Bronze Age society that thrived from approximately 3300 to 1300 BCE in the northwestern regions of South Asia. This civilization, one of the early cradles of human civilization alongside Egypt and Mesopotamia, extended across modern-day Pakistan and northwest India. It is known for its advanced city planning with well-organized cities, like Harappa and Mohenjo-Daro, containing sophisticated drainage systems, water supply systems, and clusters of large non-residential buildings. The people of IVC were skilled in various crafts, such as pottery, metallurgy, and textile manufacturing. The civilization also had its own writing system, though it remains undeciphered. The Indus Valley Civilization exhibited a relatively homogeneous culture that suggests central planning and societal unity. Around 1300 BCE, the civilization started to decline, possibly due to a combination of climate change, tectonic events, or invasion by other societies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chatgpt_summary = generate_summary_with_chatgpt()\n",
    "print(chatgpt_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb1291a1-53b7-46e7-b004-39e97f7f3556",
   "metadata": {
    "id": "cb1291a1-53b7-46e7-b004-39e97f7f3556",
    "outputId": "88663084-02e8-46c8-f72a-37f5ae934e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################## Compared to chatgpt4-generated summary ##############################\n",
      "#### TextRank ####\n",
      "rouge1 Precision: 0.06 Recall: 0.44 fmeasure: 0.11\n",
      "\n",
      "#### LSA ####\n",
      "rouge1 Precision: 0.21 Recall: 0.38 fmeasure: 0.27\n",
      "\n",
      "#### Topic Modeling ####\n",
      "rouge1 Precision: 0.36 Recall: 0.29 fmeasure: 0.32\n"
     ]
    }
   ],
   "source": [
    "# build a blank model\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "# add the gold standard and summary you want to compare\n",
    "# scores = scorer.score(gold_standard, summary)\n",
    "# print the scores\n",
    "# print_rouge_score(scores)\n",
    "\n",
    "# compare to chatgpt4-generated summary\n",
    "print(\"\\n############################## Compared to chatgpt4-generated summary ##############################\")\n",
    "print(\"#### TextRank ####\")\n",
    "print_rouge_score(scorer.score(chatgpt_summary, tr_sum))\n",
    "\n",
    "print(\"\\n#### LSA ####\")\n",
    "print_rouge_score(scorer.score(chatgpt_summary, lsa_sum))\n",
    "\n",
    "print(\"\\n#### Topic Modeling ####\")\n",
    "print_rouge_score(scorer.score(chatgpt_summary, topic_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9dc577-52a9-435b-88ac-dca9805fcf78",
   "metadata": {
    "id": "eb9dc577-52a9-435b-88ac-dca9805fcf78"
   },
   "source": [
    "#### Summary\n",
    "**&nbsp;1. Description of the analysis, the goals of the analysis, and findings.**\n",
    "\n",
    "The analysis evaluated whether traditional NLP summarization algorithms like LSA, TextRank, and Topic Modeling are as effective at generating informative and concise summaries as a state-of-the-art automated summarization tool like ChatGPT4. Using the Rouge-N analyzer, the summaries produced by each method were compared to a standard summary to assess their effectiveness, focusing on precision, recall, and f-measure as metrics.\n",
    "\n",
    "The findings revealed that while traditional summarization methods provided some useful summaries, they needed to match the performance of ChatGPT4. Specifically, the Rouge1 scores for TextRank were the lowest, with precision at 0.06, recall at 0.44, and f-measure at 0.11, indicating that it captured relevant content but lacked precision. LSA performed slightly better with precision at 0.21, recall at 0.38, and f-measure at 0.27, demonstrating a moderate capability to balance relevance and information capture. **Topic Modeling** showed the **best results** among traditional methods with precision at 0.36, recall at 0.29, and **f-measure** at **0.32**, suggesting it was the most effective at creating relevant and informative summaries. However, all these scores _still fell short compared to_ the capabilities of _ChatGPT4_, highlighting the advanced AI’s superior ability to generate more accurate and cohesive summaries.\n",
    "\n",
    "This analysis was driven by the growing need in academic and professional settings to efficiently condense large amounts of text into accessible and actionable insights. By understanding the strengths and limitations of various summarization tools, researchers and professionals can better choose the right tools for their specific needs, potentially leaning towards more advanced AI models like ChatGPT4 for tasks requiring high accuracy and depth in summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813999d-c2b8-4cda-b93d-3562d5e87632",
   "metadata": {
    "id": "a813999d-c2b8-4cda-b93d-3562d5e87632"
   },
   "source": [
    "## Sentiment Analysis using Deep Learning models (Vanilla RNN and LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5716599-52ba-4bc2-92c5-cee59c413ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5716599-52ba-4bc2-92c5-cee59c413ed8",
    "outputId": "f65e30e9-c21a-45b9-c4bd-6d9f538b2f2b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Text Preprocessing\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(DF_classify['clean2'])\n",
    "\n",
    "X = tokenizer.texts_to_sequences(DF_classify['clean2'])\n",
    "X = pad_sequences(X, maxlen=200)  # Pads or truncates the texts to be the same length\n",
    "\n",
    "# Convert labels to categorical\n",
    "sentiments = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "#y = (DF_classify['sentiment'])\n",
    "y = np.array(DF_classify['sentiment'].map(sentiments))\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef7781-16f2-4fe9-b765-eab46db540fd",
   "metadata": {
    "id": "15ef7781-16f2-4fe9-b765-eab46db540fd"
   },
   "source": [
    "#### Vanilla RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cf9eb-fde5-41f9-a4eb-9e2c32e3f8f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d92cf9eb-fde5-41f9-a4eb-9e2c32e3f8f7",
    "outputId": "e611ac38-573e-4ee1-cf6b-f979d3c4f69c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_58 (Embedding)    (None, 200, 64)           768000    \n",
      "                                                                 \n",
      " simple_rnn_44 (SimpleRNN)   (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 776451 (2.96 MB)\n",
      "Trainable params: 776451 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - 3s 384ms/step - loss: 1.1435 - accuracy: 0.3418 - val_loss: 1.0496 - val_accuracy: 0.4875\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.9755 - accuracy: 0.5696 - val_loss: 1.0164 - val_accuracy: 0.5125\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.8936 - accuracy: 0.6899 - val_loss: 1.0029 - val_accuracy: 0.5000\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 0.8055 - accuracy: 0.7943 - val_loss: 0.9838 - val_accuracy: 0.5250\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 0.7229 - accuracy: 0.8544 - val_loss: 0.9959 - val_accuracy: 0.5625\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.6496 - accuracy: 0.8956 - val_loss: 0.9900 - val_accuracy: 0.5875\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.5613 - accuracy: 0.8987 - val_loss: 0.9754 - val_accuracy: 0.5875\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 1s 130ms/step - loss: 0.4804 - accuracy: 0.9209 - val_loss: 1.0063 - val_accuracy: 0.5500\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 1s 324ms/step - loss: 0.3997 - accuracy: 0.9494 - val_loss: 0.9520 - val_accuracy: 0.5625\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.3270 - accuracy: 0.9462 - val_loss: 0.9336 - val_accuracy: 0.5875\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 0.2728 - accuracy: 0.9525 - val_loss: 0.9328 - val_accuracy: 0.5375\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 0.2162 - accuracy: 0.9747 - val_loss: 0.9764 - val_accuracy: 0.5000\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.1708 - accuracy: 0.9810 - val_loss: 0.8617 - val_accuracy: 0.6500\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.1410 - accuracy: 0.9810 - val_loss: 0.8740 - val_accuracy: 0.6125\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 0.1179 - accuracy: 0.9810 - val_loss: 0.8459 - val_accuracy: 0.6750\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.1033 - accuracy: 0.9778 - val_loss: 0.8731 - val_accuracy: 0.6500\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.0794 - accuracy: 0.9905 - val_loss: 0.8822 - val_accuracy: 0.6000\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 0.0656 - accuracy: 0.9968 - val_loss: 0.9167 - val_accuracy: 0.5750\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.9314 - val_accuracy: 0.5625\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.9180 - val_accuracy: 0.6000\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.5625\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.8905 - val_accuracy: 0.6250\n",
      "\n",
      "RNN Model Accuracy: 62.5%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(12000, 64, input_length=200))\n",
    "model_rnn.add(SimpleRNN(64))\n",
    "model_rnn.add(Dropout(0.3))\n",
    "model_rnn.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.summary()\n",
    "\n",
    "# Set up early stopping\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=False)\n",
    "\n",
    "# Train the RNN model\n",
    "history_rnn = model_rnn.fit(X_train, (y_train), epochs=25, batch_size=128,\n",
    "                            callbacks=[early_stop], validation_data=(X_test, (y_test)))\n",
    "print(\"\\nRNN Model Accuracy: {}%\".format(round((history_rnn.history['val_accuracy'][-1])*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db02ae-ff61-45f3-9459-8c8acd446156",
   "metadata": {
    "id": "34db02ae-ff61-45f3-9459-8c8acd446156"
   },
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba86e1-f438-4351-bfc7-f150b0bd70d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fba86e1-f438-4351-bfc7-f150b0bd70d4",
    "outputId": "46fdb080-4e5f-4d8e-a2ae-49464308a262"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_59 (Embedding)    (None, 200, 64)           608000    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 641219 (2.45 MB)\n",
      "Trainable params: 641219 (2.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 404ms/step - loss: 1.0974 - accuracy: 0.3228 - val_loss: 1.0856 - val_accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 1.0782 - accuracy: 0.5601 - val_loss: 1.0695 - val_accuracy: 0.4375\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 1.0556 - accuracy: 0.6297 - val_loss: 1.0458 - val_accuracy: 0.4250\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 1.0214 - accuracy: 0.6139 - val_loss: 1.0081 - val_accuracy: 0.3875\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.9763 - accuracy: 0.5063 - val_loss: 0.9959 - val_accuracy: 0.3750\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.9447 - accuracy: 0.5411 - val_loss: 0.9516 - val_accuracy: 0.6125\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 194ms/step - loss: 0.9034 - accuracy: 0.6962 - val_loss: 0.9290 - val_accuracy: 0.6375\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.8612 - accuracy: 0.6930 - val_loss: 0.9107 - val_accuracy: 0.6375\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.8000 - accuracy: 0.7089 - val_loss: 0.8733 - val_accuracy: 0.6375\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.7483 - accuracy: 0.7120 - val_loss: 0.8459 - val_accuracy: 0.6750\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.7003 - accuracy: 0.7120 - val_loss: 0.8507 - val_accuracy: 0.6375\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.6326 - accuracy: 0.7405 - val_loss: 0.8091 - val_accuracy: 0.6250\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.5675 - accuracy: 0.7690 - val_loss: 0.7877 - val_accuracy: 0.6500\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.4946 - accuracy: 0.7848 - val_loss: 0.7552 - val_accuracy: 0.6500\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.4372 - accuracy: 0.8133 - val_loss: 0.7487 - val_accuracy: 0.6625\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.3678 - accuracy: 0.8956 - val_loss: 0.7236 - val_accuracy: 0.6750\n",
      "\n",
      "LSTM Model Accuracy: 67.5%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(9500, 64, input_length=200))\n",
    "model_lstm.add(LSTM(64))\n",
    "model_rnn.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.summary()\n",
    "\n",
    "# Set up early stopping\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=False)\n",
    "\n",
    "# Train the LSTM model\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=50, batch_size=128,\n",
    "                            callbacks=[early_stop], validation_data=(X_test, (y_test)))\n",
    "print(\"\\nLSTM Model Accuracy: {}%\".format(round((history_lstm.history['val_accuracy'][-1])*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257f48d-c3ba-4604-84e0-e9725cbfdfe0",
   "metadata": {
    "id": "e257f48d-c3ba-4604-84e0-e9725cbfdfe0"
   },
   "source": [
    "#### Summary\n",
    "**&nbsp;1. Description of the analysis, the goals of the analysis, and findings. Why I was interested in running this analysis?**\n",
    "\n",
    "The analysis involved deep learning models, specifically Vanilla RNN and LSTM, to conduct sentiment analysis on the IVC dataset. This dataset included text data, which was preprocessed and labeled with sentiments (positive, neutral, negative) to be used for model training and testing. The primary goal of this analysis was to evaluate the effectiveness of these deep learning techniques in correctly classifying and understanding the sentiment of the text data.\n",
    "\n",
    "The results from this analysis, offering unique insights, showed that both models were effective to some extent, but they displayed different levels of accuracy. The `Vanilla RNN model` achieved a validation **accuracy** of approximately **62.5%**, while the `LSTM model`, with its unique capabilities, exhibited slightly better performance with an **accuracy** of around **67.5%**. These results, providing a fresh perspective, are indicative of the LSTM's enhanced ability to handle sequences and its robustness in managing longer dependencies in text data, which is crucial for sentiment analysis.\n",
    "\n",
    "This analysis was particularly interesting because it helped to compare the capabilities of the logistic regression model using bag-of-words and simple RNN architectures against more complex LSTM networks in handling natural language processing tasks such as sentiment analysis. The higher accuracy of the LSTM model reaffirmed the importance of using advanced architectures for tasks that involve understanding context over longer text sequences. This kind of analysis not only aids in selecting the right model for specific NLP tasks but also underscores the potential of using deep learning to enhance text analytics processes in various applications, from customer sentiment analysis to automating moderation in digital platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd9663-ee07-4e30-86a9-070b358cf8e4",
   "metadata": {
    "id": "0edd9663-ee07-4e30-86a9-070b358cf8e4"
   },
   "source": [
    "## Wrap Up\n",
    "\n",
    "The comprehensive analysis of the Wikipedia article about the Indus Valley Civilization utilized various NLP techniques to demonstrate the power of modern text analysis methods effectively. This included employing Named Entity Recognition (NER) to detect and categorize key entities like geographical locations and cultural terms and Keyphrase Extraction (KPE) to distill central themes such as cultural phases and significant archaeological sites. Additionally, advanced sentiment analysis was performed using deep learning architectures such as Vanilla RNN and LSTM, which aimed to discern the underlying sentiment of the textual content.\n",
    "\n",
    "The results showcased how sophisticated NLP tools could offer profound insights and a deeper understanding of extensive historical texts. For instance, LSTM models displayed a higher accuracy, pointing towards their enhanced capability in handling complex language data over simpler models like RNN. This analysis reinforces the idea that while basic NLP methods can yield significant insights, deploying more complex, advanced models is crucial when dealing with intricate and voluminous data sets typical in historical research. These tools improve the accuracy and depth of analysis and are also indispensable for extracting meaningful information from dense academic texts where precision is critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94377cc-3145-4233-a307-dea2a6d71157",
   "metadata": {
    "id": "b94377cc-3145-4233-a307-dea2a6d71157"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 (tfd)",
   "language": "python",
   "name": "tfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
